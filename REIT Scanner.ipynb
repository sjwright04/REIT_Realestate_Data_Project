{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database will be created at: C:\\Users\\0wner\\Documents\\testing colin\\version2\\data\\database\\reit_scanner.db\n",
      "✓ Database tables created successfully\n"
     ]
    }
   ],
   "source": [
    "#CORRECT VERSION 2\n",
    "\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class REITDatabase:\n",
    "    def __init__(self, db_path='version2/data/database/reit_scanner.db'):\n",
    "        self.db_path = Path(db_path)\n",
    "        self.db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.conn = None\n",
    "        print(f\"Database will be created at: {self.db_path.resolve()}\")\n",
    "    def connect(self):\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        return self.conn\n",
    "    \n",
    "    def create_tables(self):\n",
    "        \"\"\"Create all necessary tables\"\"\"\n",
    "        conn = self.connect()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Table 1: REIT Universe\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS reits (\n",
    "                ticker TEXT PRIMARY KEY,\n",
    "                company_name TEXT,\n",
    "                cik TEXT,\n",
    "                market_cap REAL,\n",
    "                sector TEXT,\n",
    "                reit_type TEXT,  -- Equity, Mortgage, Hybrid\n",
    "                geography TEXT,\n",
    "                is_active INTEGER DEFAULT 1,\n",
    "                date_added TEXT,\n",
    "                last_updated TEXT\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Table 2: SEC Filings Metadata\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS filings (\n",
    "                filing_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                ticker TEXT,\n",
    "                filing_type TEXT,  -- 10-K, 10-Q\n",
    "                filing_date TEXT,\n",
    "                period_end_date TEXT,\n",
    "                accession_number TEXT UNIQUE,\n",
    "                file_path TEXT,\n",
    "                file_url TEXT,\n",
    "                download_date TEXT,\n",
    "                processed INTEGER DEFAULT 0,\n",
    "                FOREIGN KEY (ticker) REFERENCES reits(ticker)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Table 3: Financial Metrics\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS financials (\n",
    "                metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                ticker TEXT,\n",
    "                filing_id INTEGER,\n",
    "                period_end_date TEXT,\n",
    "                \n",
    "                -- Balance Sheet\n",
    "                total_assets REAL,\n",
    "                total_debt REAL,\n",
    "                current_debt REAL,\n",
    "                long_term_debt REAL,\n",
    "                shareholders_equity REAL,\n",
    "                cash_and_equivalents REAL,\n",
    "                total_liabilities REAL,\n",
    "                \n",
    "                -- Income Statement\n",
    "                total_revenue REAL,\n",
    "                operating_income REAL,\n",
    "                interest_expense REAL,\n",
    "                net_income REAL,\n",
    "                ebitda REAL,\n",
    "                \n",
    "                -- Cash Flow\n",
    "                operating_cash_flow REAL,\n",
    "                \n",
    "                -- Calculated Ratios\n",
    "                debt_to_assets REAL,\n",
    "                debt_to_equity REAL,\n",
    "                interest_coverage REAL,\n",
    "                current_ratio REAL,\n",
    "                \n",
    "                extraction_date TEXT,\n",
    "                FOREIGN KEY (ticker) REFERENCES reits(ticker),\n",
    "                FOREIGN KEY (filing_id) REFERENCES filings(filing_id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Table 4: NLP Analysis Results\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS nlp_analysis (\n",
    "                analysis_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                ticker TEXT,\n",
    "                filing_id INTEGER,\n",
    "                distress_score REAL,  -- 0-10\n",
    "                sentiment_score REAL,  -- -1 to 1\n",
    "                analysis_date TEXT,\n",
    "                model_used TEXT,\n",
    "                FOREIGN KEY (ticker) REFERENCES reits(ticker),\n",
    "                FOREIGN KEY (filing_id) REFERENCES filings(filing_id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Table 5: Distress Flags\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS distress_flags (\n",
    "                flag_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                ticker TEXT,\n",
    "                filing_id INTEGER,\n",
    "                flag_category TEXT,  -- covenant, liquidity, asset_sale, etc.\n",
    "                severity TEXT,  -- low, medium, high, critical\n",
    "                description TEXT,\n",
    "                supporting_quote TEXT,\n",
    "                page_reference TEXT,\n",
    "                detected_date TEXT,\n",
    "                FOREIGN KEY (ticker) REFERENCES reits(ticker),\n",
    "                FOREIGN KEY (filing_id) REFERENCES filings(filing_id)\n",
    "            )\n",
    "        ''')\n",
    "\n",
    "\n",
    "                \n",
    "        # Table 6: Final Scores\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS reit_scores (\n",
    "                score_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                ticker TEXT,\n",
    "                analysis_date TEXT,\n",
    "                period_end_date TEXT,\n",
    "                \n",
    "                leverage_score REAL,\n",
    "                liquidity_score REAL,\n",
    "                distress_score REAL,\n",
    "                final_score REAL,\n",
    "                rank INTEGER,\n",
    "                \n",
    "                FOREIGN KEY (ticker) REFERENCES reits(ticker),\n",
    "                UNIQUE(ticker, analysis_date)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"✓ Database tables created successfully\")\n",
    "        \n",
    "    def close(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    db = REITDatabase()\n",
    "    db.create_tables()\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c76abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database will be created at: C:\\Users\\0wner\\Documents\\testing colin\\version2\\data\\database\\reit_scanner.db\n",
      "============================================================\n",
      "BUILDING REIT UNIVERSE\n",
      "============================================================\n",
      "Fetching REIT list from SEC...\n",
      "Columns found: ['cik_str', 'ticker', 'title']\n",
      "Total companies: 10303\n",
      "\n",
      "First few rows:\n",
      "   cik_str ticker           title\n",
      "0  1045810   NVDA     NVIDIA CORP\n",
      "1  1652044  GOOGL   Alphabet Inc.\n",
      "2   320193   AAPL      Apple Inc.\n",
      "3   789019   MSFT  MICROSOFT CORP\n",
      "4  1018724   AMZN  AMAZON COM INC\n",
      "Found 198 potential REITs\n",
      "\n",
      "Enriching with market data...\n",
      "Processing WELL... (1/198)\n",
      "Processing PLD... (2/198)\n",
      "Processing AMT... (3/198)\n",
      "Processing EQIX... (4/198)\n",
      "Processing SPG... (5/198)\n",
      "Processing O... (6/198)\n",
      "Processing DLR... (7/198)\n",
      "Processing PSA... (8/198)\n",
      "Processing CCI... (9/198)\n",
      "Processing VTR... (10/198)\n",
      "Processing EXR... (11/198)\n",
      "Processing VICI... (12/198)\n",
      "Processing AVB... (13/198)\n",
      "Processing IRM... (14/198)\n",
      "Processing EQR... (15/198)\n",
      "Processing SBAC... (16/198)\n",
      "Processing ESS... (17/198)\n",
      "Processing WY... (18/198)\n",
      "Processing MAA... (19/198)\n",
      "Processing INVH... (20/198)\n",
      "Processing SUI... (21/198)\n",
      "Processing NLY... (22/198)\n",
      "Processing WPC... (23/198)\n",
      "Processing UDR... (24/198)\n",
      "Processing KIM... (25/198)\n",
      "Processing OHI... (26/198)\n",
      "Processing AMH... (27/198)\n",
      "Processing REG... (28/198)\n",
      "Processing LAMR... (29/198)\n",
      "Processing HST... (30/198)\n",
      "Processing GLPI... (31/198)\n",
      "Processing ELS... (32/198)\n",
      "Processing AGNC... (33/198)\n",
      "Processing CPT... (34/198)\n",
      "Processing BXP... (35/198)\n",
      "Processing DOC... (36/198)\n",
      "Processing REXR... (37/198)\n",
      "Processing EGP... (38/198)\n",
      "Processing ARE... (39/198)\n",
      "Processing LINE... (40/198)\n",
      "Processing FRT... (41/198)\n",
      "Processing AHR... (42/198)\n",
      "Processing CUBE... (43/198)\n",
      "Processing CTRE... (44/198)\n",
      "Processing ADC... (45/198)\n",
      "Processing FR... (46/198)\n",
      "Processing BRX... (47/198)\n",
      "Processing NNN... (48/198)\n",
      "Processing STAG... (49/198)\n",
      "Processing VNO... (50/198)\n",
      "Processing STWD... (51/198)\n",
      "Processing RITM... (52/198)\n",
      "Processing TRNO... (53/198)\n",
      "Processing HR... (54/198)\n",
      "Processing EPRT... (55/198)\n",
      "Processing RHP... (56/198)\n",
      "Processing KRG... (57/198)\n",
      "Processing MAC... (58/198)\n",
      "Processing PECO... (59/198)\n",
      "Processing SBRA... (60/198)\n",
      "Processing KRC... (61/198)\n",
      "Processing CUZ... (62/198)\n",
      "Processing HPP... (63/198)\n",
      "Processing NSA... (64/198)\n",
      "Processing IRT... (65/198)\n",
      "Processing HASI... (66/198)\n",
      "Processing OUT... (67/198)\n",
      "Processing EPR... (68/198)\n",
      "Processing SKT... (69/198)\n",
      "Processing COLD... (70/198)\n",
      "Processing SLG... (71/198)\n",
      "Processing NHI... (72/198)\n",
      "Processing RYN... (73/198)\n",
      "Processing BNL... (74/198)\n",
      "Processing CDP... (75/198)\n",
      "Processing BXMT... (76/198)\n",
      "Processing MPW... (77/198)\n",
      "Processing PCH... (78/198)\n",
      "Processing HIW... (79/198)\n",
      "Processing DBRG... (80/198)\n",
      "Processing LXP... (81/198)\n",
      "Processing AKR... (82/198)\n",
      "Processing APLE... (83/198)\n",
      "Processing UE... (84/198)\n",
      "Processing FCPT... (85/198)\n",
      "Processing IVT... (86/198)\n",
      "Processing DEI... (87/198)\n",
      "Processing PK... (88/198)\n",
      "Processing CXW... (89/198)\n",
      "Processing DX... (90/198)\n",
      "Processing ARR... (91/198)\n",
      "Processing GNL... (92/198)\n",
      "Processing ESRT... (93/198)\n",
      "Processing DRH... (94/198)\n",
      "Processing UNIT... (95/198)\n",
      "Processing SHO... (96/198)\n",
      "Processing ESBA... (97/198)\n",
      "Processing LTC... (98/198)\n",
      "Processing NTST... (99/198)\n",
      "Processing VRE... (100/198)\n",
      "Processing ABR... (101/198)\n",
      "Processing GTY... (102/198)\n",
      "Processing NXRT... (103/198)\n",
      "Processing XHR... (104/198)\n",
      "Processing EFC... (105/198)\n",
      "Processing ALEX... (106/198)\n",
      "Processing AAT... (107/198)\n",
      "Processing PEB... (108/198)\n",
      "Processing IIPR... (109/198)\n",
      "Processing ARI... (110/198)\n",
      "Processing LADR... (111/198)\n",
      "Processing UMH... (112/198)\n",
      "Processing DHC... (113/198)\n",
      "Processing SILA... (114/198)\n",
      "Processing ORC... (115/198)\n",
      "Processing ALX... (116/198)\n",
      "Processing CSR... (117/198)\n",
      "Processing CBL... (118/198)\n",
      "Processing RLJ... (119/198)\n",
      "Processing DEA... (120/198)\n",
      "Processing TWO... (121/198)\n",
      "Processing BFS... (122/198)\n",
      "Processing PMT... (123/198)\n",
      "Processing JBGS... (124/198)\n",
      "Processing PDM... (125/198)\n",
      "Processing CIM... (126/198)\n",
      "Processing SAFE... (127/198)\n",
      "Processing PLYM... (128/198)\n",
      "Processing MFA... (129/198)\n",
      "Processing GMRE... (130/198)\n",
      "Processing AIV... (131/198)\n",
      "Processing FBRT... (132/198)\n",
      "Processing BRSP... (133/198)\n",
      "Processing STRW... (134/198)\n",
      "Processing WSR... (135/198)\n",
      "Processing RWT... (136/198)\n",
      "Processing AHH... (137/198)\n",
      "Processing TRTX... (138/198)\n",
      "Processing CTO... (139/198)\n",
      "Processing IVR... (140/198)\n",
      "Processing UHT... (141/198)\n",
      "Processing GOOD... (142/198)\n",
      "Processing PSTL... (143/198)\n",
      "Processing KREF... (144/198)\n",
      "Processing INN... (145/198)\n",
      "Processing BDN... (146/198)\n",
      "Processing PKST... (147/198)\n",
      "Processing CHCT... (148/198)\n",
      "Processing FPI... (149/198)\n",
      "Processing OLP... (150/198)\n",
      "Processing TCI... (151/198)\n",
      "Processing ILPT... (152/198)\n",
      "Processing CMTG... (153/198)\n",
      "Processing SVC... (154/198)\n",
      "Processing LAND... (155/198)\n",
      "Processing CLDT... (156/198)\n",
      "Processing RC... (157/198)\n",
      "Processing SITC... (158/198)\n",
      "Processing NREF... (159/198)\n",
      "Processing NLOP... (160/198)\n",
      "Processing CIO... (161/198)\n",
      "Processing BRT... (162/198)\n",
      "Processing MITT... (163/198)\n",
      "Processing ACRE... (164/198)\n",
      "Processing PINE... (165/198)\n",
      "Processing REFI... (166/198)\n",
      "Processing ELME... (167/198)\n",
      "Processing BHR... (168/198)\n",
      "Processing AOMR... (169/198)\n",
      "Processing EARN... (170/198)\n",
      "Processing SRG... (171/198)\n",
      "Processing NXDT... (172/198)\n",
      "Processing CLPR... (173/198)\n",
      "Processing ACR... (174/198)\n",
      "Processing MDV... (175/198)\n",
      "Processing SEVN... (176/198)\n",
      "Processing SUNS... (177/198)\n",
      "Processing ONL... (178/198)\n",
      "Processing FREVS... (179/198)\n",
      "Processing GPMT... (180/198)\n",
      "Processing CHMI... (181/198)\n",
      "Processing FSP... (182/198)\n",
      "Processing SOHO... (183/198)\n",
      "Processing LFT... (184/198)\n",
      "Processing AFCG... (185/198)\n",
      "Processing SELF... (186/198)\n",
      "Processing LOAN... (187/198)\n",
      "Processing SACH... (188/198)\n",
      "Processing BHM... (189/198)\n",
      "Processing AHT... (190/198)\n",
      "Processing NYC... (191/198)\n",
      "Processing MDRR... (192/198)\n",
      "Processing IHT... (193/198)\n",
      "Processing SQFT... (194/198)\n",
      "Processing GIPR... (195/198)\n",
      "Processing WHLR... (196/198)\n",
      "Processing CMCT... (197/198)\n",
      "Processing PW... (198/198)\n",
      "\n",
      "Applying filters...\n",
      "\n",
      "Filtered from 198 to 71 REITs\n",
      "  - Max market cap: $1,000,000,000\n",
      "  - Active trading only\n",
      "\n",
      "✓ Saved 71 REITs to database\n",
      "\n",
      "REIT Universe Summary:\n",
      "reit_type\n",
      "Equity      65\n",
      "Mortgage     6\n",
      "dtype: int64\n",
      "\n",
      "Top 10 by Market Cap:\n",
      "    ticker                          company_name  market_cap\n",
      "128    MFA                   MFA FINANCIAL, INC.   989212992\n",
      "127   PLYM        Plymouth Industrial REIT, Inc.   987534080\n",
      "129   GMRE              Global Medical REIT Inc.   960033728\n",
      "130    AIV  APARTMENT INVESTMENT & MANAGEMENT CO   848316736\n",
      "131   FBRT       Franklin BSP Realty Trust, Inc.   813286912\n",
      "132   BRSP             BrightSpire Capital, Inc.   750715008\n",
      "133   STRW          Strawberry Fields REIT, Inc.   735572736\n",
      "135    RWT                     REDWOOD TRUST INC   723005248\n",
      "134    WSR                       Whitestone REIT   716567552\n",
      "136    AHH       Armada Hoffler Properties, Inc.   711656256\n",
      "\n",
      "✓ Also saved to version2\\data\\processed\\reit_universe.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "# Use the existing REITDatabase instance if available\n",
    "if 'db' in globals() and isinstance(db, REITDatabase):\n",
    "    REITDatabase = type(db)\n",
    "\n",
    "class REITUniverseBuilder:\n",
    "    def __init__(self):\n",
    "        self.db = REITDatabase()\n",
    "        self.reits = []\n",
    "        \n",
    "    def get_reit_tickers_from_sec(self):\n",
    "        \"\"\"\n",
    "        Get REITs from SEC using EDGAR API\n",
    "        SIC Code 6798 = Real Estate Investment Trusts\n",
    "        \"\"\"\n",
    "        print(\"Fetching REIT list from SEC...\")\n",
    "        \n",
    "        # SEC Company Tickers JSON endpoint\n",
    "        url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'REIT Scanner your.email@example.com'  # Replace with your email\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Convert to DataFrame - data is dict with numeric keys\n",
    "        companies = pd.DataFrame.from_dict(data, orient='index')\n",
    "        \n",
    "        # Columns should now be: cik_str, ticker, title\n",
    "        # Let's verify and clean\n",
    "        print(f\"Columns found: {companies.columns.tolist()}\")\n",
    "        print(f\"Total companies: {len(companies)}\")\n",
    "        \n",
    "        # Filter for REITs (SIC code 6798 and 6799)\n",
    "        # Note: The JSON might not include SIC codes directly\n",
    "        # We'll need to check what's actually available\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(companies.head())\n",
    "        \n",
    "        # If SIC code isn't in the JSON, we'll need a different approach\n",
    "        tickers_list = ['AFCG','AHR','AOMR','BHM','BNL','CDP','CLPR','CMTG','EFC',\n",
    "                   'ELME','ESBA','FBRT','GIPR','GPMT','IHT','LAND','LFT','LINE',\n",
    "                   'LOAN','MDV','MITT','NLOP','NXDT','NYMT','ONL','OPI','PKST','PW','REFI',\n",
    "                   'RITM','ROIC','SACH','SILA','SQFT','STRW','SUNS','UNIT','WHLR','WSR','AAT',\n",
    "                   'ABR','ACR','ACRE','ADC','AGNC','AHH','AHT','AIRC','AIV','AJX','AKR','ALEX',\n",
    "                   'ALX','AMH','AMT','APLE','ARE','ARI','ARR','AVB','BDN','BFS','BHR','BRSP','BRT',\n",
    "                   'BRX','BXMT','BXP','CBL','CCI','CDR','CHCT','CHMI','CIM','CIO','CLDT','CMCT',\n",
    "                   'CMO','COLD','CONE','CORR','CPLG','CPT','CSR','CTO','CTRE','CTT','CUBE','CUZ',\n",
    "                   'CXP','CXW','DBRG','DCT','DEA','DEI','DHC','DLR','DOC','DRH','DX','EARN','EGP',\n",
    "                   'ELS','EPR','EPRT','EQIX','EQR','ESRT','ESS','EXR','FCPT','FPI','FR','FREVS',\n",
    "                   'FRT','FSP','GLPI','GMRE','GNL','GOOD','GTY','HASI','HIW','HPP','HR','HST','IIPR',\n",
    "                   'ILPT','INN','INVH','IRM','IRT','IVR','IVT','JBGS','KIM','KRC','KREF','KRG',\n",
    "                   'LADR','LAMR','LTC','LXP','MAA','MAC','MDRR','MFA','MPW','NHI','NLY','NNN',\n",
    "                   'NREF','NSA','NTST','NXRT','NYC','O','OHI','OLP','ORC','OUT','PCH','PDM','PEB',\n",
    "                   'PECO','PGRE','PINE','PK','PLD','PLYM','PMT','PSA','PSTL','RC','REG','REXR','RHP',\n",
    "                   'RLJ','RPAI','RWT','RYN','SAFE','SBAC','SBRA','SELF','SEVN','SHO','SITC','SKT',\n",
    "                   'SLG','SOHO','SPG','SRG','STAG','STWD','SUI','SVC','TCI','TRNO','TRTX','TWO',\n",
    "                   'UDR','UE','UHT','UMH','VER','VICI','VNO','VRE','VTR','WELL','WPC','WRE','WRI',\n",
    "                   'WY','XHR'\n",
    "]\n",
    "            \n",
    "        mask = companies['ticker'].isin(tickers_list)\n",
    "        reits = companies[mask].copy()\n",
    "        \n",
    "        print(f\"Found {len(reits)} potential REITs\")\n",
    "        return reits\n",
    "    \n",
    "    def enrich_with_market_data(self, reit_df):\n",
    "        \"\"\"Add market cap and verify these are tradable stocks\"\"\"\n",
    "        enriched_data = []\n",
    "        \n",
    "        # Use enumerate so the progress counter is always an int\n",
    "        for i, (_, row) in enumerate(reit_df.iterrows(), start=1):\n",
    "            ticker = row['ticker']\n",
    "            print(f\"Processing {ticker}... ({i}/{len(reit_df)})\")\n",
    "        \n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                info = stock.info\n",
    "                \n",
    "                # Get basic data\n",
    "                data = {\n",
    "                    'ticker': ticker,\n",
    "                    'company_name': row['title'],\n",
    "                    'cik': str(row['cik_str']).zfill(10),\n",
    "                    'market_cap': info.get('marketCap', 0),\n",
    "                    'sector': info.get('sector', 'Unknown'),\n",
    "                    'reit_type': self._classify_reit_type(row['title']),\n",
    "                    'geography': 'US',  # Can enhance this later\n",
    "                    'is_active': 1 if info.get('marketCap', 0) > 0 else 0,\n",
    "                    'date_added': datetime.now().strftime('%Y-%m-%d'),\n",
    "                    'last_updated': datetime.now().strftime('%Y-%m-%d')\n",
    "                }\n",
    "                \n",
    "                enriched_data.append(data)\n",
    "                time.sleep(0.5)  # Be nice to Yahoo Finance\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠ Error processing {ticker}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return pd.DataFrame(enriched_data)\n",
    "    \n",
    "    def _classify_reit_type(self, company_name):\n",
    "        \"\"\"Simple classification based on name\"\"\"\n",
    "        name_lower = company_name.lower()\n",
    "        \n",
    "        if any(word in name_lower for word in ['mortgage', 'mbs', 'loan']):\n",
    "            return 'Mortgage'\n",
    "        elif 'hybrid' in name_lower:\n",
    "            return 'Hybrid'\n",
    "        else:\n",
    "            return 'Equity'\n",
    "\n",
    "    def filter_universe(self, df, max_market_cap=1_000_000_000):\n",
    "        \"\"\"Apply filters to get relevant REITs\"\"\"\n",
    "        filtered = df[\n",
    "            (df['market_cap'] <= max_market_cap) &\n",
    "            (df['is_active'] == 1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"\\nFiltered from {len(df)} to {len(filtered)} REITs\")\n",
    "        print(f\"  - Max market cap: ${max_market_cap:,.0f}\")\n",
    "        print(f\"  - Active trading only\")\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    \n",
    "    def save_to_database(self, df):\n",
    "        \"\"\"Save REIT universe to database\"\"\"\n",
    "        conn = self.db.connect()\n",
    "        \n",
    "        df.to_sql('reits', conn, if_exists='replace', index=False)\n",
    "        \n",
    "        print(f\"\\n✓ Saved {len(df)} REITs to database\")\n",
    "        \n",
    "        # Show summary\n",
    "        print(\"\\nREIT Universe Summary:\")\n",
    "        print(df.groupby('reit_type').size())\n",
    "        print(f\"\\nTop 10 by Market Cap:\")\n",
    "        print(df.nlargest(10, 'market_cap')[['ticker', 'company_name', 'market_cap']])\n",
    "        \n",
    "        self.db.close()\n",
    "        \n",
    "        # Also save to CSV for easy viewing\n",
    "        output_path = Path('version2/data/processed/reit_universe.csv')\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n✓ Also saved to {output_path}\")\n",
    "    \n",
    "    def build(self, max_market_cap=1_000_000_000):\n",
    "        \"\"\"Main method to build the universe\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"BUILDING REIT UNIVERSE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Get REITs from SEC\n",
    "        sec_reits = self.get_reit_tickers_from_sec()\n",
    "        \n",
    "        # Step 2: Enrich with market data\n",
    "        print(\"\\nEnriching with market data...\")\n",
    "        enriched_reits = self.enrich_with_market_data(sec_reits)\n",
    "        \n",
    "        # Step 3: Filter\n",
    "        print(\"\\nApplying filters...\")\n",
    "        filtered_reits = self.filter_universe(enriched_reits, max_market_cap)\n",
    "        \n",
    "        # Step 4: Save\n",
    "        self.save_to_database(filtered_reits)\n",
    "        \n",
    "        return filtered_reits\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    builder = REITUniverseBuilder()\n",
    "    reits = builder.build(max_market_cap=1_000_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d392b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RE-DOWNLOADING SEC FILINGS (CORRECT FORMAT)\n",
      "============================================================\n",
      "\n",
      "Processing 71 REITs\n",
      "\n",
      "[1/71] PLYM - Plymouth Industrial REIT, Inc.\n",
      "  → 2025-03-03 - 0001171520-25-000056\n",
      "    ✓ Downloaded to 000117152025000056_10-K.html\n",
      "  → 2025-11-10 - 0001193125-25-274281\n",
      "    ✓ Downloaded to 000119312525274281_10-Q.html\n",
      "  → 2025-08-06 - 0000950170-25-104096\n",
      "  ⚠ Error getting document URL: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/viewer?action=view&cik=0001515816&accession_number=0000950170-25-104096&xbrl_type=v\n",
      "    ✗ Could not find document URL\n",
      "  → 2025-05-01 - 0001171520-25-000173\n",
      "    ✓ Downloaded to 000117152025000173_10-Q.html\n",
      "\n",
      "[2/71] MFA - MFA FINANCIAL, INC.\n",
      "  → 2025-02-20 - 0001055160-25-000004\n",
      "    ✓ Downloaded to 000105516025000004_10-K.html\n",
      "  → 2025-11-06 - 0001055160-25-000018\n",
      "    ✓ Downloaded to 000105516025000018_10-Q.html\n",
      "  → 2025-08-06 - 0001055160-25-000013\n",
      "    ✓ Downloaded to 000105516025000013_10-Q.html\n",
      "  → 2025-05-06 - 0001055160-25-000007\n",
      "    ✓ Downloaded to 000105516025000007_10-Q.html\n",
      "\n",
      "[3/71] GMRE - Global Medical REIT Inc.\n",
      "  → 2025-02-28 - 0001558370-25-001938\n",
      "    ✓ Downloaded to 000155837025001938_10-K.html\n",
      "  → 2025-11-05 - 0001104659-25-106984\n",
      "    ✓ Downloaded to 000110465925106984_10-Q.html\n",
      "  → 2025-08-06 - 0001558370-25-010515\n",
      "    ✓ Downloaded to 000155837025010515_10-Q.html\n",
      "  → 2025-05-08 - 0001558370-25-006963\n",
      "    ✓ Downloaded to 000155837025006963_10-Q.html\n",
      "\n",
      "[4/71] AIV - APARTMENT INVESTMENT & MANAGEMENT CO\n",
      "  → 2025-02-24 - 0000950170-25-025775\n",
      "    ✓ Downloaded to 000095017025025775_10-K.html\n",
      "  → 2025-11-10 - 0001193125-25-274542\n",
      "    ✓ Downloaded to 000119312525274542_10-Q.html\n",
      "  → 2025-08-11 - 0001193125-25-177967\n",
      "    ✓ Downloaded to 000119312525177967_10-Q.html\n",
      "  → 2025-05-08 - 0000950170-25-067034\n",
      "    ✓ Downloaded to 000095017025067034_10-Q.html\n",
      "\n",
      "[5/71] FBRT - Franklin BSP Realty Trust, Inc.\n",
      "  → 2025-02-26 - 0001562528-25-000013\n",
      "    ✓ Downloaded to 000156252825000013_10-K.html\n",
      "  → 2025-11-05 - 0001562528-25-000041\n",
      "    ✓ Downloaded to 000156252825000041_10-Q.html\n",
      "  → 2025-07-30 - 0001562528-25-000030\n",
      "    ✓ Downloaded to 000156252825000030_10-Q.html\n",
      "  → 2025-04-28 - 0001562528-25-000019\n",
      "    ✓ Downloaded to 000156252825000019_10-Q.html\n",
      "\n",
      "[6/71] BRSP - BrightSpire Capital, Inc.\n",
      "  → 2025-02-19 - 0001717547-25-000008\n",
      "    ✓ Downloaded to 000171754725000008_10-K.html\n",
      "  → 2025-10-29 - 0001717547-25-000083\n",
      "    ✓ Downloaded to 000171754725000083_10-Q.html\n",
      "  → 2025-07-30 - 0001717547-25-000071\n",
      "    ✓ Downloaded to 000171754725000071_10-Q.html\n",
      "  → 2025-04-30 - 0001717547-25-000048\n",
      "    ✓ Downloaded to 000171754725000048_10-Q.html\n",
      "\n",
      "[7/71] STRW - Strawberry Fields REIT, Inc.\n",
      "  → 2025-03-13 - 0001493152-25-010144\n",
      "    ✓ Downloaded to 000149315225010144_10-K.html\n",
      "  → 2025-11-06 - 0001493152-25-021088\n",
      "    ✓ Downloaded to 000149315225021088_10-Q.html\n",
      "  → 2025-08-08 - 0001641172-25-022675\n",
      "    ✓ Downloaded to 000164117225022675_10-Q.html\n",
      "  → 2025-05-09 - 0001641172-25-009352\n",
      "    ✓ Downloaded to 000164117225009352_10-Q.html\n",
      "\n",
      "[8/71] WSR - Whitestone REIT\n",
      "  → 2025-03-17 - 0001437749-25-007990\n",
      "    ✓ Downloaded to 000143774925007990_10-K.html\n",
      "  → 2025-10-31 - 0001437749-25-032581\n",
      "    ✓ Downloaded to 000143774925032581_10-Q.html\n",
      "  → 2025-08-01 - 0001437749-25-024413\n",
      "    ✓ Downloaded to 000143774925024413_10-Q.html\n",
      "  → 2025-05-05 - 0001437749-25-014553\n",
      "    ✓ Downloaded to 000143774925014553_10-Q.html\n",
      "\n",
      "[9/71] RWT - REDWOOD TRUST INC\n",
      "  → 2025-03-03 - 0000930236-25-000007\n",
      "    ✓ Downloaded to 000093023625000007_10-K.html\n",
      "  → 2025-11-07 - 0000930236-25-000037\n",
      "    ✓ Downloaded to 000093023625000037_10-Q.html\n",
      "  → 2025-08-08 - 0000930236-25-000029\n",
      "    ✓ Downloaded to 000093023625000029_10-Q.html\n",
      "  → 2025-05-09 - 0000930236-25-000020\n",
      "    ✓ Downloaded to 000093023625000020_10-Q.html\n",
      "\n",
      "[10/71] AHH - Armada Hoffler Properties, Inc.\n",
      "  → 2025-02-28 - 0001569187-25-000016\n",
      "    ✓ Downloaded to 000156918725000016_10-K.html\n",
      "  → 2025-11-05 - 0001569187-25-000180\n",
      "    ✓ Downloaded to 000156918725000180_10-Q.html\n",
      "  → 2025-08-07 - 0001569187-25-000159\n",
      "    ✓ Downloaded to 000156918725000159_10-Q.html\n",
      "  → 2025-05-09 - 0001569187-25-000070\n",
      "    ✓ Downloaded to 000156918725000070_10-Q.html\n",
      "\n",
      "[11/71] TRTX - TPG RE Finance Trust, Inc.\n",
      "  → 2025-02-18 - 0001630472-25-000005\n",
      "    ✓ Downloaded to 000163047225000005_10-K.html\n",
      "  → 2025-10-28 - 0001630472-25-000030\n",
      "    ✓ Downloaded to 000163047225000030_10-Q.html\n",
      "  → 2025-07-29 - 0001630472-25-000022\n",
      "    ✓ Downloaded to 000163047225000022_10-Q.html\n",
      "  → 2025-04-29 - 0001630472-25-000013\n",
      "    ✓ Downloaded to 000163047225000013_10-Q.html\n",
      "\n",
      "[12/71] CTO - CTO Realty Growth, Inc.\n",
      "  → 2025-02-20 - 0001558370-25-001229\n",
      "    ✓ Downloaded to 000155837025001229_10-K.html\n",
      "  → 2025-10-28 - 0001104659-25-103192\n",
      "    ✓ Downloaded to 000110465925103192_10-Q.html\n",
      "  → 2025-07-29 - 0001558370-25-009742\n",
      "    ✓ Downloaded to 000155837025009742_10-Q.html\n",
      "  → 2025-05-01 - 0001558370-25-006109\n",
      "    ✓ Downloaded to 000155837025006109_10-Q.html\n",
      "\n",
      "[13/71] IVR - Invesco Mortgage Capital Inc.\n",
      "  → 2025-02-20 - 0001437071-25-000007\n",
      "    ✓ Downloaded to 000143707125000007_10-K.html\n",
      "  → 2025-11-05 - 0001437071-25-000051\n",
      "  ⚠ Error getting document URL: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/viewer?action=view&cik=0001437071&accession_number=0001437071-25-000051&xbrl_type=v\n",
      "    ✗ Could not find document URL\n",
      "  → 2025-08-08 - 0001437071-25-000031\n",
      "    ✓ Downloaded to 000143707125000031_10-Q.html\n",
      "  → 2025-05-07 - 0001437071-25-000017\n",
      "    ✓ Downloaded to 000143707125000017_10-Q.html\n",
      "\n",
      "[14/71] UHT - UNIVERSAL HEALTH REALTY INCOME TRUST\n",
      "  → 2025-02-26 - 0000950170-25-027861\n",
      "    ✓ Downloaded to 000095017025027861_10-K.html\n",
      "  → 2025-11-07 - 0001193125-25-272382\n",
      "    ✓ Downloaded to 000119312525272382_10-Q.html\n",
      "  → 2025-08-08 - 0001193125-25-177000\n",
      "    ✓ Downloaded to 000119312525177000_10-Q.html\n",
      "  → 2025-05-08 - 0000950170-25-067009\n",
      "    ✓ Downloaded to 000095017025067009_10-Q.html\n",
      "\n",
      "[15/71] GOOD - GLADSTONE COMMERCIAL CORP\n",
      "  → 2025-02-18 - 0001234006-25-000003\n",
      "    ✓ Downloaded to 000123400625000003_10-K.html\n",
      "  → 2025-11-03 - 0001234006-25-000022\n",
      "    ✓ Downloaded to 000123400625000022_10-Q.html\n",
      "  → 2025-08-06 - 0001234006-25-000015\n",
      "    ✓ Downloaded to 000123400625000015_10-Q.html\n",
      "  → 2025-05-07 - 0001234006-25-000007\n",
      "    ✓ Downloaded to 000123400625000007_10-Q.html\n",
      "\n",
      "[16/71] PSTL - Postal Realty Trust, Inc.\n",
      "  → 2025-02-27 - 0001628280-25-008338\n",
      "    ✓ Downloaded to 000162828025008338_10-K.html\n",
      "  → 2025-11-04 - 0001628280-25-048879\n",
      "    ✓ Downloaded to 000162828025048879_10-Q.html\n",
      "  → 2025-08-04 - 0001628280-25-037487\n",
      "    ✓ Downloaded to 000162828025037487_10-Q.html\n",
      "  → 2025-05-01 - 0001628280-25-021292\n",
      "    ✓ Downloaded to 000162828025021292_10-Q.html\n",
      "\n",
      "[17/71] KREF - KKR Real Estate Finance Trust Inc.\n",
      "  → 2025-02-03 - 0001631596-25-000012\n",
      "    ✓ Downloaded to 000163159625000012_10-K.html\n",
      "  → 2025-10-21 - 0001628280-25-045722\n",
      "    ✓ Downloaded to 000162828025045722_10-Q.html\n",
      "  → 2025-07-22 - 0001631596-25-000041\n",
      "    ✓ Downloaded to 000163159625000041_10-Q.html\n",
      "  → 2025-04-23 - 0001631596-25-000029\n",
      "    ✓ Downloaded to 000163159625000029_10-Q.html\n",
      "\n",
      "[18/71] INN - Summit Hotel Properties, Inc.\n",
      "  → 2025-02-24 - 0001497645-25-000013\n",
      "    ✓ Downloaded to 000149764525000013_10-K.html\n",
      "  → 2025-11-04 - 0001497645-25-000101\n",
      "    ✓ Downloaded to 000149764525000101_10-Q.html\n",
      "  → 2025-08-05 - 0001497645-25-000091\n",
      "    ✓ Downloaded to 000149764525000091_10-Q.html\n",
      "  → 2025-04-30 - 0001497645-25-000052\n",
      "    ✓ Downloaded to 000149764525000052_10-Q.html\n",
      "\n",
      "[19/71] BDN - BRANDYWINE REALTY TRUST\n",
      "  → 2025-02-27 - 0000790816-25-000009\n",
      "    ✓ Downloaded to 000079081625000009_10-K.html\n",
      "  → 2025-11-07 - 0000790816-25-000046\n",
      "    ✓ Downloaded to 000079081625000046_10-Q.html\n",
      "  → 2025-07-28 - 0000790816-25-000034\n",
      "    ✓ Downloaded to 000079081625000034_10-Q.html\n",
      "  → 2025-04-30 - 0000790816-25-000020\n",
      "    ✓ Downloaded to 000079081625000020_10-Q.html\n",
      "\n",
      "[20/71] PKST - Peakstone Realty Trust\n",
      "  → 2025-03-27 - 0001600626-25-000025\n",
      "    ✓ Downloaded to 000160062625000025_10-K.html\n",
      "  → 2025-02-20 - 0001600626-25-000017\n",
      "    ✓ Downloaded to 000160062625000017_10-K.html\n",
      "  → 2025-11-05 - 0001628280-25-049567\n",
      "    ✓ Downloaded to 000162828025049567_10-Q.html\n",
      "  → 2025-08-07 - 0001600626-25-000067\n",
      "    ✓ Downloaded to 000160062625000067_10-Q.html\n",
      "  → 2025-05-08 - 0001600626-25-000046\n",
      "    ✓ Downloaded to 000160062625000046_10-Q.html\n",
      "\n",
      "[21/71] CHCT - Community Healthcare Trust Inc\n",
      "  → 2025-02-18 - 0001631569-25-000015\n",
      "    ✓ Downloaded to 000163156925000015_10-K.html\n",
      "  → 2025-10-28 - 0001631569-25-000091\n",
      "    ✓ Downloaded to 000163156925000091_10-Q.html\n",
      "  → 2025-07-29 - 0001628280-25-036446\n",
      "    ✓ Downloaded to 000162828025036446_10-Q.html\n",
      "  → 2025-04-29 - 0001631569-25-000030\n",
      "    ✓ Downloaded to 000163156925000030_10-Q.html\n",
      "\n",
      "[22/71] FPI - Farmland Partners Inc.\n",
      "  → 2025-02-20 - 0001558370-25-001214\n",
      "    ✓ Downloaded to 000155837025001214_10-K.html\n",
      "  → 2025-10-30 - 0001104659-25-104363\n",
      "    ✓ Downloaded to 000110465925104363_10-Q.html\n",
      "  → 2025-07-24 - 0001558370-25-009534\n",
      "    ✓ Downloaded to 000155837025009534_10-Q.html\n",
      "  → 2025-05-08 - 0001558370-25-006962\n",
      "    ✓ Downloaded to 000155837025006962_10-Q.html\n",
      "\n",
      "[23/71] OLP - ONE LIBERTY PROPERTIES INC\n",
      "  → 2025-03-06 - 0001558370-25-002406\n",
      "    ✓ Downloaded to 000155837025002406_10-K.html\n",
      "  → 2025-11-06 - 0001104659-25-107784\n",
      "    ✓ Downloaded to 000110465925107784_10-Q.html\n",
      "  → 2025-08-06 - 0001558370-25-010447\n",
      "    ✓ Downloaded to 000155837025010447_10-Q.html\n",
      "  → 2025-05-06 - 0001558370-25-006509\n",
      "    ✓ Downloaded to 000155837025006509_10-Q.html\n",
      "\n",
      "[24/71] TCI - TRANSCONTINENTAL REALTY INVESTORS INC\n",
      "  → 2025-03-20 - 0000733590-25-000004\n",
      "    ✓ Downloaded to 000073359025000004_10-K.html\n",
      "  → 2025-11-06 - 0000733590-25-000029\n",
      "    ✓ Downloaded to 000073359025000029_10-Q.html\n",
      "  → 2025-08-07 - 0000733590-25-000017\n",
      "    ✓ Downloaded to 000073359025000017_10-Q.html\n",
      "  → 2025-05-08 - 0000733590-25-000010\n",
      "    ✓ Downloaded to 000073359025000010_10-Q.html\n",
      "\n",
      "[25/71] ILPT - Industrial Logistics Properties Trust\n",
      "  → 2025-02-19 - 0001717307-25-000009\n",
      "    ✓ Downloaded to 000171730725000009_10-K.html\n",
      "  → 2025-10-28 - 0001717307-25-000038\n",
      "    ✓ Downloaded to 000171730725000038_10-Q.html\n",
      "  → 2025-07-29 - 0001717307-25-000028\n",
      "    ✓ Downloaded to 000171730725000028_10-Q.html\n",
      "  → 2025-04-29 - 0001717307-25-000016\n",
      "    ✓ Downloaded to 000171730725000016_10-Q.html\n",
      "\n",
      "[26/71] CMTG - Claros Mortgage Trust, Inc.\n",
      "  → 2025-02-19 - 0000950170-25-023258\n",
      "    ✓ Downloaded to 000095017025023258_10-K.html\n",
      "  → 2025-11-05 - 0001193125-25-266902\n",
      "    ✓ Downloaded to 000119312525266902_10-Q.html\n",
      "  → 2025-08-06 - 0000950170-25-104004\n",
      "    ✓ Downloaded to 000095017025104004_10-Q.html\n",
      "  → 2025-05-07 - 0000950170-25-065829\n",
      "    ✓ Downloaded to 000095017025065829_10-Q.html\n",
      "\n",
      "[27/71] SVC - Service Properties Trust\n",
      "  → 2025-02-26 - 0000945394-25-000014\n",
      "    ✓ Downloaded to 000094539425000014_10-K.html\n",
      "  → 2025-11-05 - 0000945394-25-000108\n",
      "    ✓ Downloaded to 000094539425000108_10-Q.html\n",
      "  → 2025-08-05 - 0000945394-25-000057\n",
      "    ✓ Downloaded to 000094539425000057_10-Q.html\n",
      "  → 2025-05-06 - 0000945394-25-000028\n",
      "    ✓ Downloaded to 000094539425000028_10-Q.html\n",
      "\n",
      "[28/71] LAND - GLADSTONE LAND Corp\n",
      "  → 2025-02-19 - 0001495240-25-000005\n",
      "    ✓ Downloaded to 000149524025000005_10-K.html\n",
      "  → 2025-11-05 - 0001495240-25-000028\n",
      "    ✓ Downloaded to 000149524025000028_10-Q.html\n",
      "  → 2025-08-07 - 0001495240-25-000021\n",
      "    ✓ Downloaded to 000149524025000021_10-Q.html\n",
      "  → 2025-05-12 - 0001495240-25-000012\n",
      "    ✓ Downloaded to 000149524025000012_10-Q.html\n",
      "\n",
      "[29/71] CLDT - Chatham Lodging Trust\n",
      "  → 2025-02-26 - 0001476045-25-000011\n",
      "    ✓ Downloaded to 000147604525000011_10-K.html\n",
      "  → 2025-11-05 - 0001437749-25-033297\n",
      "    ✓ Downloaded to 000143774925033297_10-Q.html\n",
      "  → 2025-08-06 - 0001437749-25-025025\n",
      "    ✓ Downloaded to 000143774925025025_10-Q.html\n",
      "  → 2025-05-06 - 0001437749-25-014749\n",
      "    ✓ Downloaded to 000143774925014749_10-Q.html\n",
      "\n",
      "[30/71] RC - Ready Capital Corp\n",
      "  → 2025-09-30 - 0001628280-25-043144\n",
      "    ✓ Downloaded to 000162828025043144_10-K.html\n",
      "  → 2025-03-03 - 0001628280-25-009464\n",
      "    ✓ Downloaded to 000162828025009464_10-K.html\n",
      "  → 2025-11-07 - 0001628280-25-050686\n",
      "    ✓ Downloaded to 000162828025050686_10-Q.html\n",
      "  → 2025-08-08 - 0001628280-25-039276\n",
      "    ✓ Downloaded to 000162828025039276_10-Q.html\n",
      "  → 2025-05-09 - 0001628280-25-024331\n",
      "    ✓ Downloaded to 000162828025024331_10-Q.html\n",
      "\n",
      "[31/71] SITC - SITE Centers Corp.\n",
      "  → 2025-02-28 - 0000950170-25-029989\n",
      "    ✓ Downloaded to 000095017025029989_10-K.html\n",
      "  → 2025-11-05 - 0001193125-25-267060\n",
      "    ✓ Downloaded to 000119312525267060_10-Q.html\n",
      "  → 2025-08-05 - 0000950170-25-103102\n",
      "    ✓ Downloaded to 000095017025103102_10-Q.html\n",
      "  → 2025-05-07 - 0000950170-25-065759\n",
      "    ✓ Downloaded to 000095017025065759_10-Q.html\n",
      "\n",
      "[32/71] NREF - NexPoint Real Estate Finance, Inc.\n",
      "  → 2025-03-27 - 0001786248-25-000004\n",
      "    ✓ Downloaded to 000178624825000004_10-K.html\n",
      "  → 2025-11-13 - 0001628280-25-052000\n",
      "    ✓ Downloaded to 000162828025052000_10-Q.html\n",
      "  → 2025-08-07 - 0001786248-25-000016\n",
      "    ✓ Downloaded to 000178624825000016_10-Q.html\n",
      "  → 2025-05-12 - 0001786248-25-000010\n",
      "    ✓ Downloaded to 000178624825000010_10-Q.html\n",
      "\n",
      "[33/71] NLOP - Net Lease Office Properties\n",
      "  → 2025-02-27 - 0001952976-25-000007\n",
      "    ✓ Downloaded to 000195297625000007_10-K.html\n",
      "  → 2025-11-07 - 0001952976-25-000059\n",
      "    ✓ Downloaded to 000195297625000059_10-Q.html\n",
      "  → 2025-08-06 - 0001952976-25-000048\n",
      "    ✓ Downloaded to 000195297625000048_10-Q.html\n",
      "  → 2025-05-08 - 0001952976-25-000025\n",
      "    ✓ Downloaded to 000195297625000025_10-Q.html\n",
      "\n",
      "[34/71] CIO - City Office REIT, Inc.\n",
      "  → 2025-02-20 - 0000950170-25-023714\n",
      "    ✓ Downloaded to 000095017025023714_10-K.html\n",
      "  → 2025-11-07 - 0001193125-25-270904\n",
      "    ✓ Downloaded to 000119312525270904_10-Q.html\n",
      "  → 2025-07-31 - 0000950170-25-100537\n",
      "    ✓ Downloaded to 000095017025100537_10-Q.html\n",
      "  → 2025-05-02 - 0000950170-25-062248\n",
      "    ✓ Downloaded to 000095017025062248_10-Q.html\n",
      "\n",
      "[35/71] BRT - BRT Apartments Corp.\n",
      "  → 2025-03-12 - 0000014846-25-000005\n",
      "    ✓ Downloaded to 000001484625000005_10-K.html\n",
      "  → 2025-11-06 - 0000014846-25-000037\n",
      "    ✓ Downloaded to 000001484625000037_10-Q.html\n",
      "  → 2025-08-07 - 0000014846-25-000027\n",
      "    ✓ Downloaded to 000001484625000027_10-Q.html\n",
      "  → 2025-05-08 - 0000014846-25-000012\n",
      "    ✓ Downloaded to 000001484625000012_10-Q.html\n",
      "\n",
      "[36/71] MITT - TPG Mortgage Investment Trust, Inc.\n",
      "  → 2025-03-04 - 0001514281-25-000026\n",
      "    ✓ Downloaded to 000151428125000026_10-K.html\n",
      "  → 2025-11-07 - 0001628280-25-050624\n",
      "    ✓ Downloaded to 000162828025050624_10-Q.html\n",
      "  → 2025-08-05 - 0001514281-25-000086\n",
      "  ⚠ Error getting document URL: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/viewer?action=view&cik=0001514281&accession_number=0001514281-25-000086&xbrl_type=v\n",
      "    ✗ Could not find document URL\n",
      "  → 2025-05-07 - 0001514281-25-000062\n",
      "    ✓ Downloaded to 000151428125000062_10-Q.html\n",
      "\n",
      "[37/71] ACRE - Ares Commercial Real Estate Corp\n",
      "  → 2025-02-12 - 0001628280-25-005002\n",
      "    ✓ Downloaded to 000162828025005002_10-K.html\n",
      "  → 2025-11-07 - 0001628280-25-050392\n",
      "  ⚠ Error getting document URL: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/viewer?action=view&cik=0001529377&accession_number=0001628280-25-050392&xbrl_type=v\n",
      "    ✗ Could not find document URL\n",
      "  → 2025-08-05 - 0001628280-25-037529\n",
      "    ✓ Downloaded to 000162828025037529_10-Q.html\n",
      "  → 2025-05-07 - 0001628280-25-022833\n",
      "    ✓ Downloaded to 000162828025022833_10-Q.html\n",
      "\n",
      "[38/71] PINE - Alpine Income Property Trust, Inc.\n",
      "  → 2025-02-06 - 0001558370-25-000687\n",
      "    ✓ Downloaded to 000155837025000687_10-K.html\n",
      "  → 2025-10-23 - 0001104659-25-101839\n",
      "    ✓ Downloaded to 000110465925101839_10-Q.html\n",
      "  → 2025-07-24 - 0001558370-25-009541\n",
      "    ✓ Downloaded to 000155837025009541_10-Q.html\n",
      "  → 2025-04-24 - 0001558370-25-005418\n",
      "    ✓ Downloaded to 000155837025005418_10-Q.html\n",
      "\n",
      "[39/71] REFI - Chicago Atlantic Real Estate Finance, Inc.\n",
      "  → 2025-03-12 - 0000950170-25-037616\n",
      "    ✓ Downloaded to 000095017025037616_10-K.html\n",
      "  → 2025-11-04 - 0001193125-25-263522\n",
      "    ✓ Downloaded to 000119312525263522_10-Q.html\n",
      "  → 2025-08-07 - 0000950170-25-104543\n",
      "    ✓ Downloaded to 000095017025104543_10-Q.html\n",
      "  → 2025-05-07 - 0000950170-25-064974\n",
      "    ✓ Downloaded to 000095017025064974_10-Q.html\n",
      "\n",
      "[40/71] ELME - Elme Communities\n",
      "  → 2025-02-14 - 0000104894-25-000020\n",
      "    ✓ Downloaded to 000010489425000020_10-K.html\n",
      "  → 2025-10-24 - 0000104894-25-000108\n",
      "    ✓ Downloaded to 000010489425000108_10-Q.html\n",
      "  → 2025-08-06 - 0000104894-25-000087\n",
      "    ✓ Downloaded to 000010489425000087_10-Q.html\n",
      "  → 2025-05-02 - 0000104894-25-000049\n",
      "    ✓ Downloaded to 000010489425000049_10-Q.html\n",
      "\n",
      "[41/71] BHR - Braemar Hotels & Resorts Inc.\n",
      "  ⚠ Error fetching metadata: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0001574085&type=10-K&dateb=&owner=exclude&count=2&output=atom\n",
      "  → 2025-11-07 - 0001574085-25-000130\n",
      "    ✓ Downloaded to 000157408525000130_10-Q.html\n",
      "  → 2025-08-11 - 0001574085-25-000092\n",
      "    ✓ Downloaded to 000157408525000092_10-Q.html\n",
      "  → 2025-05-08 - 0001574085-25-000051\n",
      "    ✓ Downloaded to 000157408525000051_10-Q.html\n",
      "\n",
      "[42/71] AOMR - Angel Oak Mortgage REIT, Inc.\n",
      "  → 2025-03-24 - 0001766478-25-000019\n",
      "    ✓ Downloaded to 000176647825000019_10-K.html\n",
      "  → 2025-11-06 - 0001766478-25-000099\n",
      "    ✓ Downloaded to 000176647825000099_10-Q.html\n",
      "  → 2025-08-06 - 0001766478-25-000080\n",
      "    ✓ Downloaded to 000176647825000080_10-Q.html\n",
      "  → 2025-05-06 - 0001766478-25-000042\n",
      "    ✓ Downloaded to 000176647825000042_10-Q.html\n",
      "\n",
      "[43/71] EARN - Ellington Credit Co\n",
      "  → 2025-06-23 - 0001560672-25-000074\n",
      "    ✓ Downloaded to 000156067225000074_10-K.html\n",
      "  → 2025-03-31 - 0001560672-25-000033\n",
      "    ✓ Downloaded to 000156067225000033_10-K.html\n",
      "\n",
      "[44/71] SRG - Seritage Growth Properties\n",
      "  → 2025-03-31 - 0000950170-25-047860\n",
      "    ✓ Downloaded to 000095017025047860_10-K.html\n",
      "  → 2025-11-14 - 0001193125-25-283262\n",
      "    ✓ Downloaded to 000119312525283262_10-Q.html\n",
      "  → 2025-08-14 - 0000950170-25-108985\n",
      "    ✓ Downloaded to 000095017025108985_10-Q.html\n",
      "  → 2025-05-15 - 0000950170-25-072777\n",
      "    ✓ Downloaded to 000095017025072777_10-Q.html\n",
      "\n",
      "[45/71] NXDT - NEXPOINT DIVERSIFIED REAL ESTATE TRUST\n",
      "  → 2025-03-31 - 0001356115-25-000003\n",
      "    ✓ Downloaded to 000135611525000003_10-K.html\n",
      "  → 2025-11-13 - 0001628280-25-052132\n",
      "    ✓ Downloaded to 000162828025052132_10-Q.html\n",
      "  → 2025-08-14 - 0001356115-25-000021\n",
      "    ✓ Downloaded to 000135611525000021_10-Q.html\n",
      "  → 2025-05-15 - 0001356115-25-000014\n",
      "    ✓ Downloaded to 000135611525000014_10-Q.html\n",
      "\n",
      "[46/71] CLPR - Clipper Realty Inc.\n",
      "  → 2025-02-14 - 0001437749-25-003988\n",
      "    ✓ Downloaded to 000143774925003988_10-K.html\n",
      "  → 2025-11-14 - 0001437749-25-034911\n",
      "    ✓ Downloaded to 000143774925034911_10-Q.html\n",
      "  → 2025-08-08 - 0001437749-25-025574\n",
      "    ✓ Downloaded to 000143774925025574_10-Q.html\n",
      "  → 2025-05-12 - 0001437749-25-016113\n",
      "    ✓ Downloaded to 000143774925016113_10-Q.html\n",
      "\n",
      "[47/71] ACR - ACRES Commercial Realty Corp.\n",
      "  → 2025-03-17 - 0000950170-25-039661\n",
      "    ✓ Downloaded to 000095017025039661_10-K.html\n",
      "  → 2025-11-06 - 0001193125-25-269208\n",
      "    ✓ Downloaded to 000119312525269208_10-Q.html\n",
      "  → 2025-08-05 - 0000950170-25-102890\n",
      "    ✓ Downloaded to 000095017025102890_10-Q.html\n",
      "  → 2025-05-08 - 0000950170-25-065958\n",
      "    ✓ Downloaded to 000095017025065958_10-Q.html\n",
      "\n",
      "[48/71] MDV - MODIV INDUSTRIAL, INC.\n",
      "  → 2025-03-04 - 0001645873-25-000027\n",
      "    ✓ Downloaded to 000164587325000027_10-K.html\n",
      "  → 2025-11-14 - 0001645873-25-000194\n",
      "    ✓ Downloaded to 000164587325000194_10-Q.html\n",
      "  → 2025-08-07 - 0001645873-25-000140\n",
      "    ✓ Downloaded to 000164587325000140_10-Q.html\n",
      "  → 2025-05-07 - 0001645873-25-000077\n",
      "    ✓ Downloaded to 000164587325000077_10-Q.html\n",
      "\n",
      "[49/71] SEVN - Seven Hills Realty Trust\n",
      "  → 2025-02-18 - 0001452477-25-000014\n",
      "    ✓ Downloaded to 000145247725000014_10-K.html\n",
      "  → 2025-10-27 - 0001452477-25-000052\n",
      "    ✓ Downloaded to 000145247725000052_10-Q.html\n",
      "  → 2025-07-28 - 0001452477-25-000044\n",
      "    ✓ Downloaded to 000145247725000044_10-Q.html\n",
      "  → 2025-04-28 - 0001452477-25-000025\n",
      "    ✓ Downloaded to 000145247725000025_10-Q.html\n",
      "\n",
      "[50/71] SUNS - Sunrise Realty Trust, Inc.\n",
      "  → 2025-03-06 - 0002012706-25-000004\n",
      "    ✓ Downloaded to 000201270625000004_10-K.html\n",
      "  → 2025-11-13 - 0001628280-25-051845\n",
      "    ✓ Downloaded to 000162828025051845_10-Q.html\n",
      "  → 2025-08-07 - 0002012706-25-000041\n",
      "    ✓ Downloaded to 000201270625000041_10-Q.html\n",
      "  → 2025-05-07 - 0002012706-25-000020\n",
      "    ✓ Downloaded to 000201270625000020_10-Q.html\n",
      "\n",
      "[51/71] ONL - Orion Properties Inc.\n",
      "  → 2025-03-05 - 0001873923-25-000032\n",
      "    ✓ Downloaded to 000187392325000032_10-K.html\n",
      "  → 2025-11-06 - 0001873923-25-000130\n",
      "    ✓ Downloaded to 000187392325000130_10-Q.html\n",
      "  → 2025-08-06 - 0001873923-25-000117\n",
      "    ✓ Downloaded to 000187392325000117_10-Q.html\n",
      "  → 2025-05-07 - 0001873923-25-000082\n",
      "    ✓ Downloaded to 000187392325000082_10-Q.html\n",
      "\n",
      "[52/71] FREVS - FIRST REAL ESTATE INVESTMENT TRUST OF NEW JERSEY, INC.\n",
      "  → 2025-01-29 - 0001174947-25-000074\n",
      "    ✓ Downloaded to 000117494725000074_10-K.html\n",
      "  → 2025-09-12 - 0001174947-25-001200\n",
      "    ✓ Downloaded to 000117494725001200_10-Q.html\n",
      "  → 2025-06-10 - 0001174947-25-000919\n",
      "    ✓ Downloaded to 000117494725000919_10-Q.html\n",
      "  → 2025-03-14 - 0001174947-25-000329\n",
      "    ✓ Downloaded to 000117494725000329_10-Q.html\n",
      "\n",
      "[53/71] GPMT - Granite Point Mortgage Trust Inc.\n",
      "  → 2025-02-27 - 0001703644-25-000037\n",
      "    ✓ Downloaded to 000170364425000037_10-K.html\n",
      "  → 2025-11-05 - 0001703644-25-000134\n",
      "    ✓ Downloaded to 000170364425000134_10-Q.html\n",
      "  → 2025-08-05 - 0001703644-25-000120\n",
      "    ✓ Downloaded to 000170364425000120_10-Q.html\n",
      "  → 2025-05-06 - 0001703644-25-000077\n",
      "    ✓ Downloaded to 000170364425000077_10-Q.html\n",
      "\n",
      "[54/71] CHMI - Cherry Hill Mortgage Investment Corp\n",
      "  → 2025-03-06 - 0001140361-25-007454\n",
      "    ✓ Downloaded to 000114036125007454_10-K.html\n",
      "  → 2025-11-06 - 0001140361-25-040783\n",
      "    ✓ Downloaded to 000114036125040783_10-Q.html\n",
      "  → 2025-08-07 - 0001140361-25-029603\n",
      "    ✓ Downloaded to 000114036125029603_10-Q.html\n",
      "  → 2025-05-06 - 0001140361-25-017536\n",
      "    ✓ Downloaded to 000114036125017536_10-Q.html\n",
      "\n",
      "[55/71] FSP - FRANKLIN STREET PROPERTIES CORP /MA/\n",
      "  → 2025-02-11 - 0001558370-25-000806\n",
      "    ✓ Downloaded to 000155837025000806_10-K.html\n",
      "  → 2025-10-28 - 0001104659-25-103202\n",
      "    ✓ Downloaded to 000110465925103202_10-Q.html\n",
      "  → 2025-07-29 - 0001558370-25-009745\n",
      "    ✓ Downloaded to 000155837025009745_10-Q.html\n",
      "  → 2025-04-29 - 0001558370-25-005859\n",
      "    ✓ Downloaded to 000155837025005859_10-Q.html\n",
      "\n",
      "[56/71] SOHO - Sotherly Hotels Inc.\n",
      "  → 2025-04-30 - 0000950170-25-060875\n",
      "    ✓ Downloaded to 000095017025060875_10-K.html\n",
      "  → 2025-03-31 - 0000950170-25-047657\n",
      "    ✓ Downloaded to 000095017025047657_10-K.html\n",
      "  → 2025-11-14 - 0001193125-25-282761\n",
      "    ✓ Downloaded to 000119312525282761_10-Q.html\n",
      "  → 2025-08-14 - 0001193125-25-180543\n",
      "    ✓ Downloaded to 000119312525180543_10-Q.html\n",
      "  → 2025-05-15 - 0000950170-25-072326\n",
      "    ✓ Downloaded to 000095017025072326_10-Q.html\n",
      "\n",
      "[57/71] LFT - Lument Finance Trust, Inc.\n",
      "  → 2025-03-19 - 0001628280-25-013886\n",
      "    ✓ Downloaded to 000162828025013886_10-K.html\n",
      "  → 2025-11-12 - 0001628280-25-051669\n",
      "    ✓ Downloaded to 000162828025051669_10-Q.html\n",
      "  → 2025-08-08 - 0001547546-25-000007\n",
      "    ✓ Downloaded to 000154754625000007_10-Q.html\n",
      "  → 2025-05-12 - 0001628280-25-024737\n",
      "    ✓ Downloaded to 000162828025024737_10-Q.html\n",
      "\n",
      "[58/71] AFCG - Advanced Flower Capital Inc.\n",
      "  → 2025-03-13 - 0001822523-25-000003\n",
      "    ✓ Downloaded to 000182252325000003_10-K.html\n",
      "  → 2025-11-12 - 0001628280-25-051319\n",
      "    ✓ Downloaded to 000162828025051319_10-Q.html\n",
      "  → 2025-08-14 - 0001822523-25-000027\n",
      "    ✓ Downloaded to 000182252325000027_10-Q.html\n",
      "  → 2025-05-14 - 0001822523-25-000016\n",
      "    ✓ Downloaded to 000182252325000016_10-Q.html\n",
      "\n",
      "[59/71] SELF - Global Self Storage, Inc.\n",
      "  → 2025-03-26 - 0000950170-25-045186\n",
      "    ✓ Downloaded to 000095017025045186_10-K.html\n",
      "  → 2025-11-07 - 0001193125-25-272274\n",
      "    ✓ Downloaded to 000119312525272274_10-Q.html\n",
      "  → 2025-08-08 - 0000950170-25-105798\n",
      "    ✓ Downloaded to 000095017025105798_10-Q.html\n",
      "  → 2025-05-09 - 0000950170-25-067974\n",
      "    ✓ Downloaded to 000095017025067974_10-Q.html\n",
      "\n",
      "[60/71] LOAN - MANHATTAN BRIDGE CAPITAL, INC\n",
      "  → 2025-03-12 - 0001493152-25-009931\n",
      "    ✓ Downloaded to 000149315225009931_10-K.html\n",
      "  → 2025-10-24 - 0001493152-25-019314\n",
      "    ✓ Downloaded to 000149315225019314_10-Q.html\n",
      "  → 2025-07-22 - 0001493152-25-011328\n",
      "    ✓ Downloaded to 000149315225011328_10-Q.html\n",
      "  → 2025-04-24 - 0001641172-25-005931\n",
      "    ✓ Downloaded to 000164117225005931_10-Q.html\n",
      "\n",
      "[61/71] SACH - Sachem Capital Corp.\n",
      "  → 2025-03-31 - 0001410578-25-000587\n",
      "    ✓ Downloaded to 000141057825000587_10-K.html\n",
      "  → 2025-11-05 - 0001682220-25-000070\n",
      "    ✓ Downloaded to 000168222025000070_10-Q.html\n",
      "  → 2025-08-05 - 0001682220-25-000044\n",
      "    ✓ Downloaded to 000168222025000044_10-Q.html\n",
      "  → 2025-05-01 - 0001410578-25-001059\n",
      "    ✓ Downloaded to 000141057825001059_10-Q.html\n",
      "\n",
      "[62/71] BHM - Bluerock Homes Trust, Inc.\n",
      "  → 2025-03-20 - 0001410578-25-000400\n",
      "    ✓ Downloaded to 000141057825000400_10-K.html\n",
      "  → 2025-11-06 - 0001104659-25-107723\n",
      "    ✓ Downloaded to 000110465925107723_10-Q.html\n",
      "  → 2025-08-13 - 0001410578-25-001745\n",
      "    ✓ Downloaded to 000141057825001745_10-Q.html\n",
      "  → 2025-05-09 - 0001410578-25-001149\n",
      "    ✓ Downloaded to 000141057825001149_10-Q.html\n",
      "\n",
      "[63/71] AHT - ASHFORD HOSPITALITY TRUST INC\n",
      "  → 2025-03-21 - 0001232582-25-000055\n",
      "    ✓ Downloaded to 000123258225000055_10-K.html\n",
      "  → 2025-11-13 - 0001232582-25-000167\n",
      "    ✓ Downloaded to 000123258225000167_10-Q.html\n",
      "  → 2025-08-14 - 0001232582-25-000125\n",
      "    ✓ Downloaded to 000123258225000125_10-Q.html\n",
      "  → 2025-05-14 - 0001232582-25-000093\n",
      "    ✓ Downloaded to 000123258225000093_10-Q.html\n",
      "\n",
      "[64/71] NYC - American Strategic Investment Co.\n",
      "  → 2025-03-19 - 0001628280-25-013880\n",
      "    ✓ Downloaded to 000162828025013880_10-K.html\n",
      "  → 2025-11-19 - 0001595527-25-000014\n",
      "    ✓ Downloaded to 000159552725000014_10-Q.html\n",
      "  → 2025-08-08 - 0001628280-25-039258\n",
      "    ✓ Downloaded to 000162828025039258_10-Q.html\n",
      "  → 2025-05-09 - 0001628280-25-024226\n",
      "    ✓ Downloaded to 000162828025024226_10-Q.html\n",
      "\n",
      "[65/71] MDRR - Medalist Diversified REIT, Inc.\n",
      "  → 2025-04-28 - 0001558370-25-005708\n",
      "    ✓ Downloaded to 000155837025005708_10-K.html\n",
      "  → 2025-02-27 - 0001558370-25-001807\n",
      "    ✓ Downloaded to 000155837025001807_10-K.html\n",
      "  → 2025-11-06 - 0001104659-25-107749\n",
      "    ✓ Downloaded to 000110465925107749_10-Q.html\n",
      "  → 2025-08-07 - 0001558370-25-010758\n",
      "    ✓ Downloaded to 000155837025010758_10-Q.html\n",
      "  → 2025-05-08 - 0001558370-25-006975\n",
      "    ✓ Downloaded to 000155837025006975_10-Q.html\n",
      "\n",
      "[66/71] IHT - INNSUITES HOSPITALITY TRUST\n",
      "  → 2025-05-01 - 0001641172-25-007998\n",
      "    ✓ Downloaded to 000164117225007998_10-K.html\n",
      "  → 2025-12-15 - 0001493152-25-027802\n",
      "    ✓ Downloaded to 000149315225027802_10-Q.html\n",
      "  → 2025-09-12 - 0001641172-25-027239\n",
      "    ✓ Downloaded to 000164117225027239_10-Q.html\n",
      "  → 2025-06-20 - 0001641172-25-015912\n",
      "    ✓ Downloaded to 000164117225015912_10-Q.html\n",
      "\n",
      "[67/71] SQFT - Presidio Property Trust, Inc.\n",
      "  → 2025-03-31 - 0001437749-25-010185\n",
      "    ✓ Downloaded to 000143774925010185_10-K.html\n",
      "  → 2025-11-12 - 0001437749-25-034461\n",
      "    ✓ Downloaded to 000143774925034461_10-Q.html\n",
      "  → 2025-08-14 - 0001437749-25-026786\n",
      "    ✓ Downloaded to 000143774925026786_10-Q.html\n",
      "  → 2025-05-14 - 0001437749-25-016828\n",
      "    ✓ Downloaded to 000143774925016828_10-Q.html\n",
      "\n",
      "[68/71] GIPR - GENERATION INCOME PROPERTIES, INC.\n",
      "  → 2025-04-30 - 0000950170-25-061249\n",
      "    ✓ Downloaded to 000095017025061249_10-K.html\n",
      "  → 2025-03-28 - 0000950170-25-046959\n",
      "    ✓ Downloaded to 000095017025046959_10-K.html\n",
      "  → 2025-11-14 - 0001193125-25-283340\n",
      "    ✓ Downloaded to 000119312525283340_10-Q.html\n",
      "  → 2025-08-15 - 0000950170-25-109457\n",
      "    ✓ Downloaded to 000095017025109457_10-Q.html\n",
      "  → 2025-05-15 - 0000950170-25-072868\n",
      "    ✓ Downloaded to 000095017025072868_10-Q.html\n",
      "\n",
      "[69/71] WHLR - Wheeler Real Estate Investment Trust, Inc.\n",
      "  → 2025-03-04 - 0001527541-25-000038\n",
      "    ✓ Downloaded to 000152754125000038_10-K.html\n",
      "  → 2025-11-06 - 0001527541-25-000267\n",
      "    ✓ Downloaded to 000152754125000267_10-Q.html\n",
      "  → 2025-08-05 - 0001527541-25-000194\n",
      "    ✓ Downloaded to 000152754125000194_10-Q.html\n",
      "  → 2025-05-06 - 0001527541-25-000109\n",
      "    ✓ Downloaded to 000152754125000109_10-Q.html\n",
      "\n",
      "[70/71] CMCT - Creative Media & Community Trust Corp\n",
      "  → 2025-04-30 - 0000908311-25-000030\n",
      "    ✓ Downloaded to 000090831125000030_10-K.html\n",
      "  → 2025-03-07 - 0000908311-25-000017\n",
      "    ✓ Downloaded to 000090831125000017_10-K.html\n",
      "  → 2025-11-14 - 0000908311-25-000096\n",
      "    ✓ Downloaded to 000090831125000096_10-Q.html\n",
      "  → 2025-08-14 - 0000908311-25-000067\n",
      "    ✓ Downloaded to 000090831125000067_10-Q.html\n",
      "  → 2025-05-09 - 0000908311-25-000038\n",
      "    ✓ Downloaded to 000090831125000038_10-Q.html\n",
      "\n",
      "[71/71] PW - Power REIT\n",
      "  → 2025-03-31 - 0001641172-25-001515\n",
      "    ✓ Downloaded to 000164117225001515_10-K.html\n",
      "  → 2025-10-24 - 0001493152-25-019229\n",
      "    ✓ Downloaded to 000149315225019229_10-Q.html\n",
      "  → 2025-08-05 - 0001641172-25-022295\n",
      "    ✓ Downloaded to 000164117225022295_10-Q.html\n",
      "  → 2025-05-14 - 0001641172-25-010329\n",
      "    ✓ Downloaded to 000164117225010329_10-Q.html\n",
      "\n",
      "============================================================\n",
      "DOWNLOAD COMPLETE\n",
      "============================================================\n",
      "Downloaded: 283\n",
      "Errors: 4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class SECFilingDownloader:\n",
    "    def __init__(self, db_path='version2/data/database/reit_scanner.db'):\n",
    "        self.db_path = db_path\n",
    "        self.headers = {\n",
    "            'User-Agent': 'REIT Scanner tennesseesamwright999@gmail.com',  # Replace with your email\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "        }\n",
    "        self.base_url = \"https://www.sec.gov\"\n",
    "        \n",
    "    def get_reit_list(self):\n",
    "        \"\"\"Get list of REITs from database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        df = pd.read_sql(\"SELECT ticker, cik, company_name FROM reits WHERE is_active = 1\", conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def get_filing_documents(self, accession_number, cik):\n",
    "        \"\"\"\n",
    "        Get the actual document URL (not the viewer wrapper)\n",
    "        \"\"\"\n",
    "        # Clean accession number (remove dashes)\n",
    "        acc_clean = accession_number.replace('-', '')\n",
    "        cik_clean = str(cik).replace('-', '').zfill(10)\n",
    "        \n",
    "        # This is the filing detail page\n",
    "        index_url = f\"{self.base_url}/cgi-bin/viewer?action=view&cik={cik_clean}&accession_number={accession_number}&xbrl_type=v\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(index_url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            time.sleep(0.15)\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the table with document links\n",
    "            table = soup.find('table', {'summary': 'Document Format Files'})\n",
    "            if not table:\n",
    "                table = soup.find('table', {'class': 'tableFile'})\n",
    "            \n",
    "            if table:\n",
    "                rows = table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cells = row.find_all('td')\n",
    "                    if len(cells) >= 3:\n",
    "                        # Look for the main document (10-K or 10-Q)\n",
    "                        doc_type = cells[3].text.strip() if len(cells) > 3 else ''\n",
    "                        \n",
    "                        if '10-K' in doc_type or '10-Q' in doc_type:\n",
    "                            # Get the document link\n",
    "                            link = cells[2].find('a')\n",
    "                            if link and link.get('href'):\n",
    "                                doc_url = link['href']\n",
    "                                # Make sure it's not the viewer wrapper\n",
    "                                if not 'ix?doc=' in doc_url:\n",
    "                                    if not doc_url.startswith('http'):\n",
    "                                        doc_url = f\"{self.base_url}{doc_url}\"\n",
    "                                    return doc_url\n",
    "            \n",
    "            # Fallback: try direct URL construction\n",
    "            # Pattern: /Archives/edgar/version2/data/{cik}/{accession-no-dashes}/{filename}\n",
    "            fallback_url = f\"{self.base_url}/Archives/edgar/data/{cik_clean.lstrip('0')}/{acc_clean}/{accession_number}.txt\"\n",
    "            return fallback_url\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error getting document URL: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def download_filing(self, doc_url, ticker, accession_number, filing_type):\n",
    "        \"\"\"Download the actual filing document\"\"\"\n",
    "        try:\n",
    "            response = requests.get(doc_url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            time.sleep(0.15)\n",
    "            \n",
    "            # Save to file\n",
    "            save_path = Path(f'version2/data/raw/filings/{ticker}')\n",
    "            save_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            filename = f\"{accession_number.replace('-', '')}_{filing_type.replace('/', '_')}.html\"\n",
    "            file_path = save_path / filename\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            return str(file_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error downloading: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_company_filings_metadata(self, cik, filing_type, count=2):\n",
    "        \"\"\"Get filing metadata from SEC\"\"\"\n",
    "        cik_clean = str(cik).replace('-', '').zfill(10)\n",
    "        \n",
    "        url = f\"{self.base_url}/cgi-bin/browse-edgar\"\n",
    "        params = {\n",
    "            'action': 'getcompany',\n",
    "            'CIK': cik_clean,\n",
    "            'type': filing_type,\n",
    "            'dateb': '',\n",
    "            'owner': 'exclude',\n",
    "            'count': count,\n",
    "            'output': 'atom'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            time.sleep(0.15)\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'xml')\n",
    "            entries = soup.find_all('entry')\n",
    "            \n",
    "            filings = []\n",
    "            for entry in entries:\n",
    "                accession = entry.find('accession-number')\n",
    "                filing_date = entry.find('filing-date')\n",
    "                \n",
    "                if accession and filing_date:\n",
    "                    filings.append({\n",
    "                        'accession_number': accession.text,\n",
    "                        'filing_date': filing_date.text,\n",
    "                        'filing_type': filing_type\n",
    "                    })\n",
    "            \n",
    "            return filings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error fetching metadata: {e}\")\n",
    "            return []\n",
    "    \n",
    "  \n",
    "    def save_filing_to_db(self, ticker, filing_type, filing_date, accession_number, file_path, file_url):\n",
    "        \"\"\"Save filing metadata to database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute('''\n",
    "                INSERT OR REPLACE INTO filings\n",
    "                (ticker, filing_type, filing_date, accession_number, file_path, file_url, download_date)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                ticker,\n",
    "                filing_type,\n",
    "                filing_date,\n",
    "                accession_number,\n",
    "                file_path,\n",
    "                file_url,\n",
    "                datetime.now().strftime('%Y-%m-%d')\n",
    "            ))\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"    ⚠ Error saving to database: {e}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    def download_filings(self, limit_companies):\n",
    "        \"\"\"\n",
    "        Re-download filings with correct document URLs\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"RE-DOWNLOADING SEC FILINGS (CORRECT FORMAT)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        reits = self.get_reit_list()\n",
    "        \n",
    "        if limit_companies:\n",
    "            reits = reits.head(limit_companies)\n",
    "            print(f\"\\n⚠ Testing with first {limit_companies} companies\")\n",
    "        \n",
    "        print(f\"\\nProcessing {len(reits)} REITs\\n\")\n",
    "        \n",
    "        total_downloaded = 0\n",
    "        total_errors = 0\n",
    "        \n",
    "        for idx, row in reits.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            cik = row['cik']\n",
    "            company = row['company_name']\n",
    "            \n",
    "            print(f\"[{idx+1}/{len(reits)}] {ticker} - {company}\")\n",
    "            \n",
    "            # Get most recent 2 10-K filings\n",
    "            filings_10k = self.get_company_filings_metadata(cik, '10-K', 2)\n",
    "            filings_10q = self.get_company_filings_metadata(cik, '10-Q', 2)\n",
    "\n",
    "            for filing in filings_10k:\n",
    "                if filing['filing_date'] < '2025-01-01':\n",
    "                    continue\n",
    "                \n",
    "                acc_num = filing['accession_number']\n",
    "                filing_date = filing['filing_date']\n",
    "                print(f\"  → {filing_date} - {acc_num}\")\n",
    "                \n",
    "                # Get actual document URL\n",
    "                doc_url = self.get_filing_documents(acc_num, cik)\n",
    "                \n",
    "                if doc_url:\n",
    "                    # Download the document\n",
    "                    file_path = self.download_filing(\n",
    "                        doc_url, ticker, acc_num, '10-K'\n",
    "                    )\n",
    "                    \n",
    "                    if file_path:\n",
    "                        print(f\"    ✓ Downloaded to {Path(file_path).name}\")\n",
    "                        # Save to database with file_url\n",
    "                        self.save_filing_to_db(ticker, '10-K', filing_date, acc_num, file_path, doc_url)\n",
    "                        total_downloaded += 1\n",
    "                    else:\n",
    "                        total_errors += 1\n",
    "                        print(f\"    ✗ Download failed\")\n",
    "                else:\n",
    "                    total_errors += 1\n",
    "                    print(f\"    ✗ Could not find document URL\")\n",
    "            \n",
    "            for filing in filings_10q:\n",
    "                if filing['filing_date'] < '2025-01-01':\n",
    "                    continue\n",
    "                \n",
    "                acc_num = filing['accession_number']\n",
    "                filing_date = filing['filing_date']\n",
    "                print(f\"  → {filing_date} - {acc_num}\")\n",
    "                \n",
    "                # Get actual document URL\n",
    "                doc_url = self.get_filing_documents(acc_num, cik)\n",
    "                \n",
    "                if doc_url:\n",
    "                    # Download the document\n",
    "                    file_path = self.download_filing(\n",
    "                        doc_url, ticker, acc_num, '10-Q'\n",
    "                    )\n",
    "                    \n",
    "                    if file_path:\n",
    "                        print(f\"    ✓ Downloaded to {Path(file_path).name}\")\n",
    "                        # Save to database with file_url\n",
    "                        self.save_filing_to_db(ticker, '10-Q', filing_date, acc_num, file_path, doc_url)\n",
    "                        total_downloaded += 1\n",
    "                    else:\n",
    "                        total_errors += 1\n",
    "                        print(f\"    ✗ Download failed\")\n",
    "                else:\n",
    "                    total_errors += 1\n",
    "                    print(f\"    ✗ Could not find document URL\")\n",
    "\n",
    "            print()\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"DOWNLOAD COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Downloaded: {total_downloaded}\")\n",
    "        print(f\"Errors: {total_errors}\")\n",
    "        \n",
    "        return total_downloaded, total_errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    downloader = SECFilingDownloader()\n",
    "    \n",
    "    # Test with 5 companies first\n",
    "    downloader.download_filings(limit_companies=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "988ae615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTING FINANCIAL DATA VIA SEC API\n",
      "============================================================\n",
      "\n",
      "Processing 71 REITs\n",
      "\n",
      "[1/71] PLYM - Plymouth Industrial REIT, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1004 data points across 75 periods\n",
      "\n",
      "[2/71] MFA - MFA FINANCIAL, INC.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1344 data points across 118 periods\n",
      "\n",
      "[3/71] GMRE - Global Medical REIT Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1027 data points across 95 periods\n",
      "\n",
      "[4/71] AIV - APARTMENT INVESTMENT & MANAGEMENT CO\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1655 data points across 117 periods\n",
      "\n",
      "[5/71] FBRT - Franklin BSP Realty Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1238 data points across 82 periods\n",
      "\n",
      "[6/71] BRSP - BrightSpire Capital, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 731 data points across 46 periods\n",
      "\n",
      "[7/71] STRW - Strawberry Fields REIT, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 297 data points across 23 periods\n",
      "\n",
      "[8/71] WSR - Whitestone REIT\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1366 data points across 122 periods\n",
      "\n",
      "[9/71] RWT - REDWOOD TRUST INC\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1404 data points across 114 periods\n",
      "\n",
      "[10/71] AHH - Armada Hoffler Properties, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1316 data points across 85 periods\n",
      "\n",
      "[11/71] TRTX - TPG RE Finance Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 713 data points across 50 periods\n",
      "\n",
      "[12/71] CTO - CTO Realty Growth, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1609 data points across 101 periods\n",
      "\n",
      "[13/71] IVR - Invesco Mortgage Capital Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1267 data points across 110 periods\n",
      "\n",
      "[14/71] UHT - UNIVERSAL HEALTH REALTY INCOME TRUST\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1383 data points across 110 periods\n",
      "\n",
      "[15/71] GOOD - GLADSTONE COMMERCIAL CORP\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1331 data points across 107 periods\n",
      "\n",
      "[16/71] PSTL - Postal Realty Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 568 data points across 38 periods\n",
      "\n",
      "[17/71] KREF - KKR Real Estate Finance Trust Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 672 data points across 76 periods\n",
      "\n",
      "[18/71] INN - Summit Hotel Properties, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1503 data points across 109 periods\n",
      "\n",
      "[19/71] BDN - BRANDYWINE REALTY TRUST\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1480 data points across 116 periods\n",
      "\n",
      "[20/71] PKST - Peakstone Realty Trust\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1195 data points across 82 periods\n",
      "\n",
      "[21/71] CHCT - Community Healthcare Trust Inc\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 927 data points across 68 periods\n",
      "\n",
      "[22/71] FPI - Farmland Partners Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 861 data points across 87 periods\n",
      "\n",
      "[23/71] OLP - ONE LIBERTY PROPERTIES INC\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1426 data points across 122 periods\n",
      "\n",
      "[24/71] TCI - TRANSCONTINENTAL REALTY INVESTORS INC\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1389 data points across 115 periods\n",
      "\n",
      "[25/71] ILPT - Industrial Logistics Properties Trust\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 629 data points across 56 periods\n",
      "\n",
      "[26/71] CMTG - Claros Mortgage Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 387 data points across 32 periods\n",
      "\n",
      "[27/71] SVC - Service Properties Trust\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1663 data points across 115 periods\n",
      "\n",
      "[28/71] LAND - GLADSTONE LAND Corp\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1194 data points across 92 periods\n",
      "\n",
      "[29/71] CLDT - Chatham Lodging Trust\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1351 data points across 109 periods\n",
      "\n",
      "[30/71] RC - Ready Capital Corp\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 827 data points across 97 periods\n",
      "\n",
      "[31/71] SITC - SITE Centers Corp.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1382 data points across 115 periods\n",
      "\n",
      "[32/71] NREF - NexPoint Real Estate Finance, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 250 data points across 28 periods\n",
      "\n",
      "[33/71] NLOP - Net Lease Office Properties\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 166 data points across 16 periods\n",
      "\n",
      "[34/71] CIO - City Office REIT, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1152 data points across 85 periods\n",
      "\n",
      "[35/71] BRT - BRT Apartments Corp.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1501 data points across 123 periods\n",
      "\n",
      "[36/71] MITT - TPG Mortgage Investment Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1218 data points across 111 periods\n",
      "\n",
      "[37/71] ACRE - Ares Commercial Real Estate Corp\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1090 data points across 94 periods\n",
      "\n",
      "[38/71] PINE - Alpine Income Property Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 528 data points across 35 periods\n",
      "\n",
      "[39/71] REFI - Chicago Atlantic Real Estate Finance, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 303 data points across 24 periods\n",
      "\n",
      "[40/71] ELME - Elme Communities\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1635 data points across 130 periods\n",
      "\n",
      "[41/71] BHR - Braemar Hotels & Resorts Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1184 data points across 87 periods\n",
      "\n",
      "[42/71] AOMR - Angel Oak Mortgage REIT, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 332 data points across 30 periods\n",
      "\n",
      "[43/71] EARN - Ellington Credit Co\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 982 data points across 94 periods\n",
      "\n",
      "[44/71] SRG - Seritage Growth Properties\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 873 data points across 70 periods\n",
      "\n",
      "[45/71] NXDT - NEXPOINT DIVERSIFIED REAL ESTATE TRUST\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 299 data points across 27 periods\n",
      "\n",
      "[46/71] CLPR - Clipper Realty Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 743 data points across 63 periods\n",
      "\n",
      "[47/71] ACR - ACRES Commercial Realty Corp.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1354 data points across 119 periods\n",
      "\n",
      "[48/71] MDV - MODIV INDUSTRIAL, INC.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 819 data points across 60 periods\n",
      "\n",
      "[49/71] SEVN - Seven Hills Realty Trust\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 396 data points across 28 periods\n",
      "\n",
      "[50/71] SUNS - Sunrise Realty Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 91 data points across 13 periods\n",
      "\n",
      "[51/71] ONL - Orion Properties Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 273 data points across 28 periods\n",
      "\n",
      "[52/71] FREVS - FIRST REAL ESTATE INVESTMENT TRUST OF NEW JERSEY, INC.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1534 data points across 121 periods\n",
      "\n",
      "[53/71] GPMT - Granite Point Mortgage Trust Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 688 data points across 65 periods\n",
      "\n",
      "[54/71] CHMI - Cherry Hill Mortgage Investment Corp\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 859 data points across 95 periods\n",
      "\n",
      "[55/71] FSP - FRANKLIN STREET PROPERTIES CORP /MA/\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1332 data points across 111 periods\n",
      "\n",
      "[56/71] SOHO - Sotherly Hotels Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1534 data points across 124 periods\n",
      "\n",
      "[57/71] LFT - Lument Finance Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 959 data points across 93 periods\n",
      "\n",
      "[58/71] AFCG - Advanced Flower Capital Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 322 data points across 28 periods\n",
      "\n",
      "[59/71] SELF - Global Self Storage, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 946 data points across 51 periods\n",
      "\n",
      "[60/71] LOAN - MANHATTAN BRIDGE CAPITAL, INC\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1085 data points across 79 periods\n",
      "\n",
      "[61/71] SACH - Sachem Capital Corp.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 611 data points across 48 periods\n",
      "\n",
      "[62/71] BHM - Bluerock Homes Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 227 data points across 21 periods\n",
      "\n",
      "[63/71] AHT - ASHFORD HOSPITALITY TRUST INC\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1469 data points across 116 periods\n",
      "\n",
      "[64/71] NYC - American Strategic Investment Co.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1124 data points across 86 periods\n",
      "\n",
      "[65/71] MDRR - Medalist Diversified REIT, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 553 data points across 38 periods\n",
      "\n",
      "[66/71] IHT - INNSUITES HOSPITALITY TRUST\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1255 data points across 82 periods\n",
      "\n",
      "[67/71] SQFT - Presidio Property Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1056 data points across 79 periods\n",
      "\n",
      "[68/71] GIPR - GENERATION INCOME PROPERTIES, INC.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 344 data points across 30 periods\n",
      "\n",
      "[69/71] WHLR - Wheeler Real Estate Investment Trust, Inc.\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1287 data points across 80 periods\n",
      "\n",
      "[70/71] CMCT - Creative Media & Community Trust Corp\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1426 data points across 104 periods\n",
      "\n",
      "[71/71] PW - Power REIT\n",
      "  Fetching company facts from SEC API...\n",
      "  ✓ Extracted 1152 data points across 77 periods\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Successfully processed: 71/71\n",
      "Failed: 0/71\n",
      "Total financial periods saved: 5577\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "class FinancialDataExtractor:\n",
    "    def __init__(self, db_path='version2/data/database/reit_scanner.db'):\n",
    "        self.db_path = db_path\n",
    "        self.headers = {\n",
    "            'User-Agent': 'REIT Scanner tennesseesamwright999@gmail.com',\n",
    "        }\n",
    "        \n",
    "    def get_reit_list(self):\n",
    "        \"\"\"Get list of REITs with CIK numbers\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        df = pd.read_sql(\"SELECT ticker, cik, company_name FROM reits WHERE is_active = 1\", conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def get_company_facts(self, cik):\n",
    "        \"\"\"\n",
    "        Get structured financial data from SEC's Company Facts API\n",
    "        This returns XBRL data in JSON format - much more reliable!\n",
    "        \"\"\"\n",
    "        cik_clean = str(cik).replace('-', '').zfill(10)\n",
    "        url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik_clean}.json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            time.sleep(0.1)  # Be nice to SEC\n",
    "            \n",
    "            data = response.json()\n",
    "            return data\n",
    "            \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                print(f\"  ⚠ No XBRL data available for CIK {cik}\")\n",
    "            else:\n",
    "                print(f\"  ⚠ Error fetching company facts: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_financial_metrics(self, facts_data):\n",
    "        \"\"\"\n",
    "        Extract key financial metrics from SEC Company Facts JSON\n",
    "        \n",
    "        The structure is:\n",
    "        facts['dei'] - document and entity info\n",
    "        facts['us-gaap'] - US GAAP financial metrics\n",
    "        \"\"\"\n",
    "        if not facts_data or 'facts' not in facts_data:\n",
    "            return []\n",
    "        \n",
    "        metrics_map = {\n",
    "            # Balance Sheet\n",
    "            'Assets': 'total_assets',\n",
    "            'LongTermDebt': 'long_term_debt',\n",
    "            'DebtCurrent': 'current_debt',\n",
    "            'Liabilities': 'total_liabilities',\n",
    "            'StockholdersEquity': 'shareholders_equity',\n",
    "            'CashAndCashEquivalentsAtCarryingValue': 'cash_and_equivalents',\n",
    "            \n",
    "            # Income Statement\n",
    "            'Revenues': 'total_revenue',\n",
    "            'OperatingIncomeLoss': 'operating_income',\n",
    "            'InterestExpense': 'interest_expense',\n",
    "            'NetIncomeLoss': 'net_income',\n",
    "            \n",
    "            # Cash Flow\n",
    "            'NetCashProvidedByUsedInOperatingActivities': 'operating_cash_flow',\n",
    "        }\n",
    "        \n",
    "        us_gaap = facts_data['facts'].get('us-gaap', {})\n",
    "        \n",
    "        # Collect all data points\n",
    "        all_metrics = []\n",
    "        \n",
    "        for gaap_tag, metric_name in metrics_map.items():\n",
    "            if gaap_tag not in us_gaap:\n",
    "                continue\n",
    "            \n",
    "            metric_data = us_gaap[gaap_tag]\n",
    "            \n",
    "            # Get the 10-K and 10-Q filings data\n",
    "            units = metric_data.get('units', {})\n",
    "            \n",
    "            # Most financial metrics are in USD\n",
    "            usd_data = units.get('USD', [])\n",
    "            \n",
    "            for data_point in usd_data:\n",
    "                # Only get annual (10-K) and quarterly (10-Q) data\n",
    "                form = data_point.get('form')\n",
    "                if form not in ['10-K', '10-Q']:\n",
    "                    continue\n",
    "                \n",
    "                all_metrics.append({\n",
    "                    'metric_name': metric_name,\n",
    "                    'value': data_point.get('val'),\n",
    "                    'period_end': data_point.get('end'),\n",
    "                    'filing_date': data_point.get('filed'),\n",
    "                    'form': form,\n",
    "                    'fiscal_year': data_point.get('fy'),\n",
    "                    'fiscal_period': data_point.get('fp'),\n",
    "                })\n",
    "        \n",
    "        return all_metrics\n",
    "    \n",
    "    def save_metrics_to_db(self, ticker, cik, metrics):\n",
    "        \"\"\"Save extracted metrics to database\"\"\"\n",
    "        if not metrics:\n",
    "            return 0\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Group metrics by period\n",
    "        periods = {}\n",
    "        for metric in metrics:\n",
    "            period_key = (metric['period_end'], metric['form'])\n",
    "            if period_key not in periods:\n",
    "                periods[period_key] = {\n",
    "                    'period_end_date': metric['period_end'],\n",
    "                    'filing_form': metric['form'],\n",
    "                    'filing_date': metric['filing_date'],\n",
    "                    'fiscal_year': metric['fiscal_year'],\n",
    "                    'fiscal_period': metric['fiscal_period'],\n",
    "                }\n",
    "            \n",
    "            periods[period_key][metric['metric_name']] = metric['value']\n",
    "        \n",
    "        # Insert each period\n",
    "        saved = 0\n",
    "        for period_data in periods.values():\n",
    "            try:\n",
    "                cursor.execute('''\n",
    "                    INSERT OR REPLACE INTO financials \n",
    "                    (ticker, period_end_date, \n",
    "                     total_assets, long_term_debt, current_debt,\n",
    "                     total_liabilities, shareholders_equity, cash_and_equivalents,\n",
    "                     total_revenue, operating_income, interest_expense, net_income,\n",
    "                     operating_cash_flow, extraction_date)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (\n",
    "                    ticker,\n",
    "                    period_data['period_end_date'],\n",
    "                    period_data.get('total_assets'),\n",
    "                    period_data.get('long_term_debt'),\n",
    "                    period_data.get('current_debt'),\n",
    "                    period_data.get('total_liabilities'),\n",
    "                    period_data.get('shareholders_equity'),\n",
    "                    period_data.get('cash_and_equivalents'),\n",
    "                    period_data.get('total_revenue'),\n",
    "                    period_data.get('operating_income'),\n",
    "                    period_data.get('interest_expense'),\n",
    "                    period_data.get('net_income'),\n",
    "                    period_data.get('operating_cash_flow'),\n",
    "                    datetime.now().strftime('%Y-%m-%d')\n",
    "                ))\n",
    "                saved += 1\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠ Error saving period {period_data['period_end_date']}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        return saved\n",
    "    \n",
    "    def process_all_reits(self, limit=None):\n",
    "        \"\"\"\n",
    "        Main method to extract financial data for all REITs\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"EXTRACTING FINANCIAL DATA VIA SEC API\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        reits = self.get_reit_list()\n",
    "        \n",
    "        if limit:\n",
    "            reits = reits.head(limit)\n",
    "            print(f\"\\n⚠ Processing only first {limit} REITs for testing\")\n",
    "        \n",
    "        print(f\"\\nProcessing {len(reits)} REITs\\n\")\n",
    "        \n",
    "        successful = 0\n",
    "        failed = 0\n",
    "        total_periods = 0\n",
    "        \n",
    "        for idx, row in reits.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            cik = row['cik']\n",
    "            company = row['company_name']\n",
    "            \n",
    "            print(f\"[{idx+1}/{len(reits)}] {ticker} - {company}\")\n",
    "            \n",
    "            # Get structured financial data from SEC API\n",
    "            print(\"  Fetching company facts from SEC API...\")\n",
    "            facts = self.get_company_facts(cik)\n",
    "            \n",
    "            if facts:\n",
    "                metrics = self.extract_financial_metrics(facts)\n",
    "                \n",
    "                if metrics:\n",
    "                    saved = self.save_metrics_to_db(ticker, cik, metrics)\n",
    "                    print(f\"  ✓ Extracted {len(metrics)} data points across {saved} periods\")\n",
    "                    total_periods += saved\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    print(f\"  ⚠ No financial metrics found in XBRL data\")\n",
    "                    failed += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"EXTRACTION COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Successfully processed: {successful}/{len(reits)}\")\n",
    "        print(f\"Failed: {failed}/{len(reits)}\")\n",
    "        print(f\"Total financial periods saved: {total_periods}\")\n",
    "        print(f\"Success rate: {successful/len(reits)*100:.1f}%\")\n",
    "        \n",
    "        return successful, failed\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = FinancialDataExtractor()\n",
    "    extractor.process_all_reits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73026a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CALCULATING FINANCIAL RATIOS & SCORES\n",
      "============================================================\n",
      "\n",
      "Loading financial data...\n",
      "Loaded 10887 financial records for 71 REITs\n",
      "\n",
      "Calculating leverage and liquidity ratios...\n",
      "Getting most recent data for each REIT...\n",
      "Processing 71 REITs\n",
      "\n",
      "Calculating risk scores...\n",
      "\n",
      "Saving scores to database...\n",
      "\n",
      "============================================================\n",
      "TOP 20 MOST AT-RISK REITs (by financial metrics)\n",
      "============================================================\n",
      "ticker period_end_date  financial_score  leverage_score  liquidity_score  debt_to_assets  interest_coverage  cash_to_debt\n",
      "  MDRR      2025-09-30             92.5             100               85        0.690647           0.574280      0.029659\n",
      "  SOHO      2025-09-30             92.5             100               85        0.779108           0.092408      0.029430\n",
      "  STRW      2025-09-30             82.5              80               85        0.884988           1.652522      0.025412\n",
      "   ACR      2025-09-30             80.0              95               65        0.706957           0.638497      0.034281\n",
      "   AHT      2025-09-30             80.0              75               85        0.867646        -612.630435      0.031377\n",
      "   BDN      2025-09-30             80.0              95               65        0.683693           0.955876      0.033258\n",
      "  ILPT      2025-09-30             77.5              55              100        0.804167           5.461994      0.019818\n",
      "  AOMR      2025-09-30             75.0              65               85        0.838517                NaN      0.023325\n",
      "  GOOD      2025-09-30             75.0              65               85        0.666627                NaN      0.021819\n",
      "   AHH      2025-09-30             72.5              80               65        0.576476           1.299026      0.031307\n",
      "   IHT      2025-10-31             70.0             100               40        0.811908          -1.354214      0.136309\n",
      "   BHR      2025-09-30             65.0              60               70        0.579636                NaN      0.099838\n",
      "  CMCT      2025-09-30             65.0              80               50        0.605358          -0.403536      0.032818\n",
      "  TRTX      2025-09-30             62.5              60               65        0.724949                NaN      0.031760\n",
      "   MDV      2025-09-30             60.0              70               50        0.559966           1.194869      0.029541\n",
      "  NREF      2025-09-30             60.0              35               85        0.136584                NaN      0.024859\n",
      "  PSTL      2025-09-30             60.0              55               65        0.471985           1.475046      0.005481\n",
      "   AIV      2025-09-30             57.5              65               50        0.398952           1.299722      0.488067\n",
      "  BRSP      2025-09-30             55.0              60               50        0.656947                NaN      0.052227\n",
      "  CMTG      2025-09-30             55.0              60               50        0.671833                NaN      0.092871\n",
      "\n",
      "✓ Saved full results to version2/data/processed/reit_risk_scores.csv\n",
      "\n",
      "============================================================\n",
      "RISK SCORE DISTRIBUTION\n",
      "============================================================\n",
      "count    71.000000\n",
      "mean     38.908451\n",
      "std      24.697211\n",
      "min       0.000000\n",
      "25%      20.000000\n",
      "50%      35.000000\n",
      "75%      56.250000\n",
      "max      92.500000\n",
      "Name: financial_score, dtype: float64\n",
      "\n",
      "============================================================\n",
      "KEY METRICS SUMMARY\n",
      "============================================================\n",
      "REITs with Debt/Assets > 60%: 15\n",
      "REITs with Interest Coverage < 2.0x: 27\n",
      "REITs with Cash/Debt < 5%: 23\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class RatioCalculator:\n",
    "    def __init__(self, db_path='version2/data/database/reit_scanner.db'):\n",
    "        self.db_path = db_path\n",
    "    \n",
    "    def get_financial_data(self):\n",
    "        \"\"\"Get all financial data from database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        \n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                ticker,\n",
    "                period_end_date,\n",
    "                total_assets,\n",
    "                long_term_debt,\n",
    "                current_debt,\n",
    "                total_liabilities,\n",
    "                shareholders_equity,\n",
    "                cash_and_equivalents,\n",
    "                total_revenue,\n",
    "                operating_income,\n",
    "                interest_expense,\n",
    "                net_income,\n",
    "                operating_cash_flow\n",
    "            FROM financials\n",
    "            WHERE total_assets IS NOT NULL\n",
    "            ORDER BY ticker, period_end_date DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_all_ratios(self, df):\n",
    "        \"\"\"Calculate leverage and liquidity ratios\"\"\"\n",
    "        \n",
    "        # Calculate total debt (long-term + current)\n",
    "        df['total_debt'] = df['long_term_debt'].fillna(0) + df['current_debt'].fillna(0)\n",
    "        \n",
    "        # Replace zeros with NaN to avoid division errors\n",
    "        df['total_assets'] = df['total_assets'].replace(0, np.nan)\n",
    "        df['shareholders_equity'] = df['shareholders_equity'].replace(0, np.nan)\n",
    "        df['interest_expense'] = df['interest_expense'].replace(0, np.nan)\n",
    "        df['total_revenue'] = df['total_revenue'].replace(0, np.nan)\n",
    "        \n",
    "        # Leverage Ratios\n",
    "        df['debt_to_assets'] = df['total_debt'] / df['total_assets']\n",
    "        df['debt_to_equity'] = df['total_debt'] / df['shareholders_equity']\n",
    "        \n",
    "        # Coverage Ratios\n",
    "        # Interest Coverage = Operating Income / Interest Expense\n",
    "        df['interest_coverage'] = df['operating_income'] / df['interest_expense']\n",
    "        \n",
    "        # Liquidity Ratios\n",
    "        df['cash_to_debt'] = df['cash_and_equivalents'] / df['total_debt']\n",
    "        \n",
    "        # Additional useful metrics\n",
    "        df['equity_ratio'] = df['shareholders_equity'] / df['total_assets']\n",
    "        df['leverage_ratio'] = df['total_assets'] / df['shareholders_equity']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_most_recent_by_ticker(self, df):\n",
    "        \"\"\"Get most recent financial period for each REIT\"\"\"\n",
    "        # Sort by ticker and date, then take the first (most recent) for each ticker\n",
    "        df_sorted = df.sort_values(['ticker', 'period_end_date'], ascending=[True, False])\n",
    "        most_recent = df_sorted.groupby('ticker').first().reset_index()\n",
    "        \n",
    "        return most_recent\n",
    "    \n",
    "    def calculate_leverage_score(self, row):\n",
    "        \"\"\"\n",
    "        Calculate leverage score (0-100, higher = more risk)\n",
    "        Based on debt/assets, debt/equity, and interest coverage\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # Debt to Assets (weight: 30 points)\n",
    "        debt_assets = row['debt_to_assets']\n",
    "        if pd.notna(debt_assets):\n",
    "            if debt_assets > 0.65:  # Very high leverage\n",
    "                score += 30\n",
    "            elif debt_assets > 0.55:\n",
    "                score += 25\n",
    "            elif debt_assets > 0.45:\n",
    "                score += 15\n",
    "            elif debt_assets > 0.35:\n",
    "                score += 5\n",
    "        \n",
    "        # Debt to Equity (weight: 25 points)\n",
    "        debt_equity = row['debt_to_equity']\n",
    "        if pd.notna(debt_equity):\n",
    "            if debt_equity > 3.0:  # Very high\n",
    "                score += 25\n",
    "            elif debt_equity > 2.0:\n",
    "                score += 20\n",
    "            elif debt_equity > 1.5:\n",
    "                score += 10\n",
    "            elif debt_equity > 1.0:\n",
    "                score += 5\n",
    "        \n",
    "        # Interest Coverage (weight: 45 points) - MOST IMPORTANT\n",
    "        int_cov = row['interest_coverage']\n",
    "        if pd.notna(int_cov):\n",
    "            if int_cov < 1.0:  # Not covering interest!\n",
    "                score += 45\n",
    "            elif int_cov < 1.5:  # Barely covering\n",
    "                score += 35\n",
    "            elif int_cov < 2.0:\n",
    "                score += 25\n",
    "            elif int_cov < 2.5:\n",
    "                score += 15\n",
    "            elif int_cov < 3.0:\n",
    "                score += 5\n",
    "        else:\n",
    "            # No interest expense data - could be concerning\n",
    "            score += 10\n",
    "        \n",
    "        return min(score, 100)  # Cap at 100\n",
    "    \n",
    "    def calculate_liquidity_score(self, row):\n",
    "        \"\"\"\n",
    "        Calculate liquidity score (0-100, higher = more risk)\n",
    "        Based on cash position relative to debt\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # Cash to Debt ratio (lower = worse)\n",
    "        cash_debt = row['cash_to_debt']\n",
    "        if pd.notna(cash_debt):\n",
    "            if cash_debt < 0.02:  # Less than 2% cash coverage\n",
    "                score += 50\n",
    "            elif cash_debt < 0.05:  # Less than 5%\n",
    "                score += 35\n",
    "            elif cash_debt < 0.10:  # Less than 10%\n",
    "                score += 20\n",
    "            elif cash_debt < 0.15:\n",
    "                score += 10\n",
    "        else:\n",
    "            score += 25  # No data is concerning\n",
    "        \n",
    "        # Equity Ratio (lower = worse)\n",
    "        equity_ratio = row['equity_ratio']\n",
    "        if pd.notna(equity_ratio):\n",
    "            if equity_ratio < 0.20:  # Less than 20% equity\n",
    "                score += 50\n",
    "            elif equity_ratio < 0.30:\n",
    "                score += 30\n",
    "            elif equity_ratio < 0.40:\n",
    "                score += 15\n",
    "            elif equity_ratio < 0.50:\n",
    "                score += 5\n",
    "        \n",
    "        return min(score, 100)\n",
    "    \n",
    "    def process_all_reits(self):\n",
    "        \"\"\"Main method to calculate ratios and scores\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"CALCULATING FINANCIAL RATIOS & SCORES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get data\n",
    "        print(\"\\nLoading financial data...\")\n",
    "        df = self.get_financial_data()\n",
    "        print(f\"Loaded {len(df)} financial records for {df['ticker'].nunique()} REITs\")\n",
    "        \n",
    "        # Calculate ratios\n",
    "        print(\"\\nCalculating leverage and liquidity ratios...\")\n",
    "        df_with_ratios = self.calculate_all_ratios(df)\n",
    "        \n",
    "        # Get most recent period for each REIT\n",
    "        print(\"Getting most recent data for each REIT...\")\n",
    "        most_recent = self.get_most_recent_by_ticker(df_with_ratios)\n",
    "        print(f\"Processing {len(most_recent)} REITs\")\n",
    "        \n",
    "        # Calculate scores\n",
    "        print(\"\\nCalculating risk scores...\")\n",
    "        most_recent['leverage_score'] = most_recent.apply(self.calculate_leverage_score, axis=1)\n",
    "        most_recent['liquidity_score'] = most_recent.apply(self.calculate_liquidity_score, axis=1)\n",
    "        \n",
    "        # Composite score (we'll add NLP distress score later)\n",
    "        # For now: 50% leverage, 50% liquidity\n",
    "        most_recent['financial_score'] = (\n",
    "            most_recent['leverage_score'] * 0.5 +\n",
    "            most_recent['liquidity_score'] * 0.5\n",
    "        )\n",
    "        \n",
    "        # Rank REITs\n",
    "        most_recent['rank'] = most_recent['financial_score'].rank(ascending=False, method='dense').astype(int)\n",
    "        \n",
    "        # Save to database\n",
    "        print(\"\\nSaving scores to database...\")\n",
    "        self.save_scores(most_recent)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TOP 20 MOST AT-RISK REITs (by financial metrics)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        top_risk = most_recent.nlargest(20, 'financial_score')[[\n",
    "            'ticker', 'period_end_date', 'financial_score', 'leverage_score', \n",
    "            'liquidity_score', 'debt_to_assets', 'interest_coverage', 'cash_to_debt'\n",
    "        ]]\n",
    "        \n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        print(top_risk.to_string(index=False))\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_path = 'version2/data/processed/reit_risk_scores.csv'\n",
    "        most_recent.to_csv(output_path, index=False)\n",
    "        print(f\"\\n✓ Saved full results to {output_path}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RISK SCORE DISTRIBUTION\")\n",
    "        print(\"=\"*60)\n",
    "        print(most_recent['financial_score'].describe())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"KEY METRICS SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"REITs with Debt/Assets > 60%: {(most_recent['debt_to_assets'] > 0.6).sum()}\")\n",
    "        print(f\"REITs with Interest Coverage < 2.0x: {(most_recent['interest_coverage'] < 2.0).sum()}\")\n",
    "        print(f\"REITs with Cash/Debt < 5%: {(most_recent['cash_to_debt'] < 0.05).sum()}\")\n",
    "        \n",
    "        return most_recent\n",
    "    \n",
    "    def save_scores(self, df):\n",
    "        \"\"\"Save scores to database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            cursor.execute('''\n",
    "                INSERT OR REPLACE INTO reit_scores\n",
    "                (ticker, analysis_date, period_end_date, \n",
    "                 leverage_score, liquidity_score, final_score, rank)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                row['ticker'],\n",
    "                datetime.now().strftime('%Y-%m-%d'),\n",
    "                row['period_end_date'],\n",
    "                row['leverage_score'],\n",
    "                row['liquidity_score'],\n",
    "                row['financial_score'],\n",
    "                row['rank']\n",
    "            ))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    calculator = RatioCalculator()\n",
    "    results = calculator.process_all_reits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f611af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTING TEXT SECTIONS\n",
      "============================================================\n",
      "\n",
      "Found 285 10-K and 10-Q files across 71 REITs\n",
      "Processing 285 files\n",
      "\n",
      "[0/285] ACR...\n",
      "[20/285] AIV...\n",
      "[40/285] BRSP...\n",
      "[60/285] CLDT...\n",
      "[80/285] EARN...\n",
      "[100/285] FSP...\n",
      "[120/285] IHT...\n",
      "[140/285] LAND...\n",
      "[160/285] MFA...\n",
      "[180/285] NYC...\n",
      "[200/285] PLYM...\n",
      "[220/285] RWT...\n",
      "[240/285] SOHO...\n",
      "[260/285] SUNS...\n",
      "[280/285] WHLR...\n",
      "\n",
      "============================================================\n",
      "TEXT EXTRACTION COMPLETE\n",
      "============================================================\n",
      "MD&A sections extracted: 24\n",
      "Risk sections extracted: 261\n",
      "REITs with text data: 71\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "class TextSectionExtractor:\n",
    "    def __init__(self):\n",
    "        self.filings_dir = Path('version2/data/raw/filings')\n",
    "    \n",
    "    def get_all_10k_files(self):\n",
    "        \"\"\"Get all 10-K and 10-Q files from the new download directory\"\"\"\n",
    "        all_files = []\n",
    "        \n",
    "        for ticker_folder in self.filings_dir.iterdir():\n",
    "            if ticker_folder.is_dir():\n",
    "                ticker = ticker_folder.name\n",
    "                for file in ticker_folder.glob('*_10-[KQ].html'):\n",
    "                    all_files.append({\n",
    "                        'ticker': ticker,\n",
    "                        'file_path': str(file),\n",
    "                        'filename': file.name\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(all_files)\n",
    "    \n",
    "    def extract_text_from_html(self, file_path):\n",
    "        \"\"\"Extract clean text from HTML filing\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            \n",
    "            # Remove scripts, styles\n",
    "            for element in soup(['script', 'style']):\n",
    "                element.decompose()\n",
    "            \n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_sections(self, text):\n",
    "        \"\"\"Extract MD&A and Risk Factors\"\"\"\n",
    "        mda = None\n",
    "        risks = None\n",
    "        \n",
    "        # MD&A patterns\n",
    "        mda_patterns = [\n",
    "            r\"ITEM\\s*7[\\s\\.:\\-–—]*MANAGEMENT['\\']?S?\\s+DISCUSSION\",\n",
    "            r\"Item\\s*7[\\s\\.:\\-–—]*Management['\\']?s?\\s+Discussion\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in mda_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                start = match.start()\n",
    "                # Get next 30k chars\n",
    "                mda = text[start:start+30000]\n",
    "                break\n",
    "        \n",
    "        # Risk Factors patterns\n",
    "        risk_patterns = [\n",
    "            r\"ITEM\\s*1A[\\s\\.:\\-–—]*RISK\\s+FACTORS\",\n",
    "            r\"Item\\s*1A[\\s\\.:\\-–—]*Risk\\s+Factors\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in risk_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                start = match.start()\n",
    "                risks = text[start:start+30000]\n",
    "                break\n",
    "        \n",
    "        return mda, risks\n",
    "    \n",
    "    def process_all_filings(self, limit_reits=None):\n",
    "        \"\"\"Extract text from all 10-K and 10-Q filings\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"EXTRACTING TEXT SECTIONS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        files_df = self.get_all_10k_files()\n",
    "        print(f\"\\nFound {len(files_df)} 10-K and 10-Q files across {files_df['ticker'].nunique()} REITs\")\n",
    "        \n",
    "\n",
    "        if limit_reits:\n",
    "            tickers = files_df['ticker'].unique()[:limit_reits]\n",
    "            files_df = files_df[files_df['ticker'].isin(tickers)]\n",
    "            print(f\"\\n⚠ Processing only {limit_reits} REITs for testing\")\n",
    "        \n",
    "        print(f\"Processing {len(files_df)} files\\n\")\n",
    "        \n",
    "        mda_count = 0\n",
    "        risk_count = 0\n",
    "        \n",
    "        for idx, row in files_df.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            file_path = row['file_path']\n",
    "            \n",
    "            if idx % 20 == 0:\n",
    "                print(f\"[{idx}/{len(files_df)}] {ticker}...\")\n",
    "            \n",
    "            text = self.extract_text_from_html(file_path)\n",
    "            if not text or len(text) < 5000:\n",
    "                continue\n",
    "            \n",
    "            mda, risks = self.extract_sections(text)\n",
    "            \n",
    "            if mda or risks:\n",
    "                text_dir = Path(f'version2/data/processed/text_sections/{ticker}')\n",
    "                text_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                file_id = Path(file_path).stem.split('_')[0]\n",
    "                \n",
    "                if mda and len(mda) > 1000:\n",
    "                    with open(text_dir / f'{file_id}_mda.txt', 'w', encoding='utf-8') as f:\n",
    "                        f.write(mda)\n",
    "                    mda_count += 1\n",
    "                \n",
    "                if risks and len(risks) > 1000:\n",
    "                    with open(text_dir / f'{file_id}_risks.txt', 'w', encoding='utf-8') as f:\n",
    "                        f.write(risks)\n",
    "                    risk_count += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TEXT EXTRACTION COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"MD&A sections extracted: {mda_count}\")\n",
    "        print(f\"Risk sections extracted: {risk_count}\")\n",
    "        \n",
    "        text_dir = Path('version2/data/processed/text_sections')\n",
    "        if text_dir.exists():\n",
    "            reits = [d.name for d in text_dir.iterdir() if d.is_dir()]\n",
    "            print(f\"REITs with text data: {len(reits)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = TextSectionExtractor()\n",
    "    extractor.process_all_filings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "170a9135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NLP DISTRESS ANALYSIS (UF NAVIGATOR)\n",
      "============================================================\n",
      "[1/71] Analyzing ACR\n",
      "  Distress Score: 6.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[2/71] Analyzing ACRE\n",
      "  Distress Score: 3 | Confidence: medium\n",
      "  Flags Found: 2\n",
      "[3/71] Analyzing AFCG\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[4/71] Analyzing AHH\n",
      "  Distress Score: 6.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[5/71] Analyzing AHT\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[6/71] Analyzing AIV\n",
      "  Distress Score: 7.5 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[7/71] Analyzing AOMR\n",
      "  Distress Score: 6.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[8/71] Analyzing BDN\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[9/71] Analyzing BHM\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[10/71] Analyzing BHR\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[11/71] Analyzing BRSP\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[12/71] Analyzing BRT\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 4\n",
      "[13/71] Analyzing CHCT\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[14/71] Analyzing CHMI\n",
      "  Distress Score: 2 | Confidence: medium\n",
      "  Flags Found: 0\n",
      "[15/71] Analyzing CIO\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[16/71] Analyzing CLDT\n",
      "  Distress Score: 2 | Confidence: medium\n",
      "  Flags Found: 2\n",
      "[17/71] Analyzing CLPR\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[18/71] Analyzing CMCT\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[19/71] Analyzing CMTG\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[20/71] Analyzing CTO\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 5\n",
      "[21/71] Analyzing EARN\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[22/71] Analyzing ELME\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[23/71] Analyzing FBRT\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[24/71] Analyzing FPI\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[25/71] Analyzing FREVS\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[26/71] Analyzing FSP\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[27/71] Analyzing GIPR\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[28/71] Analyzing GMRE\n",
      "  Distress Score: 7.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[29/71] Analyzing GOOD\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[30/71] Analyzing GPMT\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 4\n",
      "[31/71] Analyzing IHT\n",
      "  Distress Score: 7.5 | Confidence: high\n",
      "  Flags Found: 5\n",
      "[32/71] Analyzing ILPT\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[33/71] Analyzing INN\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 5\n",
      "[34/71] Analyzing IVR\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[35/71] Analyzing KREF\n",
      "  Distress Score: 3 | Confidence: medium\n",
      "  Flags Found: 3\n",
      "[36/71] Analyzing LAND\n",
      "  Distress Score: 6.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[37/71] Analyzing LFT\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[38/71] Analyzing LOAN\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 4\n",
      "[39/71] Analyzing MDRR\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[40/71] Analyzing MDV\n",
      "  Distress Score: 7.5 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[41/71] Analyzing MFA\n",
      "  Distress Score: 5.7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[42/71] Analyzing MITT\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[43/71] Analyzing NLOP\n",
      "  Distress Score: 7.5 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[44/71] Analyzing NREF\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[45/71] Analyzing NXDT\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[46/71] Analyzing NYC\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 5\n",
      "[47/71] Analyzing OLP\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[48/71] Analyzing ONL\n",
      "  Distress Score: 7.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[49/71] Analyzing PINE\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[50/71] Analyzing PKST\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 4\n",
      "[51/71] Analyzing PLYM\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[52/71] Analyzing PSTL\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[53/71] Analyzing PW\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[54/71] Analyzing RC\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[55/71] Analyzing REFI\n",
      "  Distress Score: 2 | Confidence: medium\n",
      "  Flags Found: 3\n",
      "[56/71] Analyzing RWT\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[57/71] Analyzing SACH\n",
      "  Distress Score: 2 | Confidence: medium\n",
      "  Flags Found: 1\n",
      "[58/71] Analyzing SELF\n",
      "  Distress Score: 2 | Confidence: medium\n",
      "  Flags Found: 3\n",
      "[59/71] Analyzing SEVN\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 4\n",
      "[60/71] Analyzing SITC\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[61/71] Analyzing SOHO\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[62/71] Analyzing SQFT\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[63/71] Analyzing SRG\n",
      "  Distress Score: 8 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[64/71] Analyzing STRW\n",
      "  Distress Score: 5 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[65/71] Analyzing SUNS\n",
      "  Distress Score: 6.7 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[66/71] Analyzing SVC\n",
      "  Distress Score: 7.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[67/71] Analyzing TCI\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 5\n",
      "[68/71] Analyzing TRTX\n",
      "  Distress Score: 7 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[69/71] Analyzing UHT\n",
      "  Distress Score: 7 | Confidence: high\n",
      "  Flags Found: 6\n",
      "[70/71] Analyzing WHLR\n",
      "  Distress Score: 6 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "[71/71] Analyzing WSR\n",
      "  Distress Score: 6.5 | Confidence: medium\n",
      "  Flags Found: 6\n",
      "\n",
      "✅ NLP distress analysis complete\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# SET YOUR UF NAVIGATOR / OPENAI API KEY HERE\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-tbJgticiapFJTC4vMiHnhQ\"\n",
    "\n",
    "\n",
    "class NLPDistressAnalyzer:\n",
    "    def __init__(self, db_path='version2/data/database/reit_scanner.db'):\n",
    "        self.db_path = db_path\n",
    "\n",
    "        # UF Navigator / LiteLLM OpenAI-compatible client\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            base_url=\"https://api.ai.it.ufl.edu\"\n",
    "        )\n",
    "\n",
    "    def get_reits_with_text_sections(self):\n",
    "        text_dir = Path('version2/data/processed/text_sections')\n",
    "        if not text_dir.exists():\n",
    "            return []\n",
    "\n",
    "        return [\n",
    "            folder.name\n",
    "            for folder in text_dir.iterdir()\n",
    "            if folder.is_dir() and any(folder.glob('*'))\n",
    "        ]\n",
    "\n",
    "    def analyze_filing_text(self, ticker, mda_text=None, risk_text=None):\n",
    "        if not mda_text and not risk_text:\n",
    "            return None\n",
    "\n",
    "        combined_text = \"\"\n",
    "        if mda_text:\n",
    "            combined_text += f\"MD&A SECTION:\\n{mda_text[:8000]}\\n\\n\"\n",
    "        if risk_text:\n",
    "            combined_text += f\"RISK FACTORS:\\n{risk_text[:7000]}\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a financial analyst specializing in REIT distress analysis.\n",
    "\n",
    "Analyze the following excerpts from {ticker}'s 10-K filing for signs of financial distress or forced asset sales.\n",
    "\n",
    "Look for:\n",
    "1. Covenant violations or risks\n",
    "2. Liquidity concerns\n",
    "3. Forced asset sales\n",
    "4. Debt maturity pressures\n",
    "5. Operational deterioration\n",
    "6. Going concern warnings\n",
    "\n",
    "Filing Text:\n",
    "{combined_text}\n",
    "\n",
    "Respond ONLY with valid JSON (no markdown):\n",
    "\n",
    "{{\n",
    "  \"distress_score\": <0-10>,\n",
    "  \"confidence\": \"<high|medium|low>\",\n",
    "  \"key_flags\": [\n",
    "    {{\n",
    "      \"category\": \"<covenant_risk|liquidity|asset_sale|debt_maturity|operational|going_concern>\",\n",
    "      \"severity\": \"<critical|high|medium|low>\",\n",
    "      \"description\": \"<brief description>\",\n",
    "      \"supporting_quote\": \"<relevant excerpt>\"\n",
    "    }}\n",
    "  ],\n",
    "  \"summary\": \"<2-3 sentence summary>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-oss-120b\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2\n",
    "            )\n",
    "\n",
    "            response_text = response.choices[0].message.content\n",
    "            response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "            return json.loads(response_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error analyzing {ticker}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_nlp_analysis(self, ticker, filing_id, analysis):\n",
    "        if not analysis:\n",
    "            return\n",
    "\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO nlp_analysis\n",
    "            (ticker, filing_id, distress_score, sentiment_score,\n",
    "             analysis_date, model_used)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            ticker,\n",
    "            filing_id,\n",
    "            analysis.get('distress_score'),\n",
    "            None,\n",
    "            datetime.now().strftime('%Y-%m-%d'),\n",
    "            'gpt-oss-120b'\n",
    "        ))\n",
    "\n",
    "        for flag in analysis.get('key_flags', []):\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO distress_flags\n",
    "                (ticker, filing_id, flag_category, severity,\n",
    "                 description, supporting_quote, detected_date)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                ticker,\n",
    "                filing_id,\n",
    "                flag.get('category'),\n",
    "                flag.get('severity'),\n",
    "                flag.get('description'),\n",
    "                flag.get('supporting_quote'),\n",
    "                datetime.now().strftime('%Y-%m-%d')\n",
    "            ))\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    def process_all_reits(self, limit=None):\n",
    "        print(\"=\" * 60)\n",
    "        print(\"NLP DISTRESS ANALYSIS (UF NAVIGATOR)\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        reits = self.get_reits_with_text_sections()\n",
    "\n",
    "        if limit:\n",
    "            reits = reits[:limit]\n",
    "            print(f\"\\n⚠ Running in test mode: {limit} REITs\\n\")\n",
    "\n",
    "        for idx, ticker in enumerate(reits, 1):\n",
    "            print(f\"[{idx}/{len(reits)}] Analyzing {ticker}\")\n",
    "\n",
    "            text_dir = Path(f'version2/data/processed/text_sections/{ticker}')\n",
    "            mda_files = sorted(text_dir.glob('*_mda.txt'), reverse=True)\n",
    "            risk_files = sorted(text_dir.glob('*_risks.txt'), reverse=True)\n",
    "\n",
    "            mda_text = None\n",
    "            risk_text = None\n",
    "            filing_id = None\n",
    "\n",
    "            if mda_files:\n",
    "                filing_id = mda_files[0].stem.split('_')[0]\n",
    "                mda_text = mda_files[0].read_text(encoding='utf-8')\n",
    "\n",
    "            if risk_files:\n",
    "                if not filing_id:\n",
    "                    filing_id = risk_files[0].stem.split('_')[0]\n",
    "                risk_text = risk_files[0].read_text(encoding='utf-8')\n",
    "\n",
    "            analysis = self.analyze_filing_text(ticker, mda_text, risk_text)\n",
    "\n",
    "            if analysis:\n",
    "                print(f\"  Distress Score: {analysis['distress_score']} | Confidence: {analysis['confidence']}\")\n",
    "                print(f\"  Flags Found: {len(analysis.get('key_flags', []))}\")\n",
    "                self.save_nlp_analysis(ticker, filing_id, analysis)\n",
    "\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        print(\"\\n✅ NLP distress analysis complete\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analyzer = NLPDistressAnalyzer()\n",
    "\n",
    "analyzer.process_all_reits()\n",
    "\n",
    "# Full run (later)\n",
    "# analyzer.process_all_reits()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d549f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>cik</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>sector</th>\n",
       "      <th>reit_type</th>\n",
       "      <th>geography</th>\n",
       "      <th>is_active</th>\n",
       "      <th>date_added</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLYM</td>\n",
       "      <td>Plymouth Industrial REIT, Inc.</td>\n",
       "      <td>0001515816</td>\n",
       "      <td>987534080</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFA</td>\n",
       "      <td>MFA FINANCIAL, INC.</td>\n",
       "      <td>0001055160</td>\n",
       "      <td>989212992</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMRE</td>\n",
       "      <td>Global Medical REIT Inc.</td>\n",
       "      <td>0001533615</td>\n",
       "      <td>960033728</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIV</td>\n",
       "      <td>APARTMENT INVESTMENT &amp; MANAGEMENT CO</td>\n",
       "      <td>0000922864</td>\n",
       "      <td>848316736</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FBRT</td>\n",
       "      <td>Franklin BSP Realty Trust, Inc.</td>\n",
       "      <td>0001562528</td>\n",
       "      <td>813286912</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SQFT</td>\n",
       "      <td>Presidio Property Trust, Inc.</td>\n",
       "      <td>0001080657</td>\n",
       "      <td>5202343</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GIPR</td>\n",
       "      <td>GENERATION INCOME PROPERTIES, INC.</td>\n",
       "      <td>0001651721</td>\n",
       "      <td>4491688</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WHLR</td>\n",
       "      <td>Wheeler Real Estate Investment Trust, Inc.</td>\n",
       "      <td>0001527541</td>\n",
       "      <td>3217630</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>CMCT</td>\n",
       "      <td>Creative Media &amp; Community Trust Corp</td>\n",
       "      <td>0000908311</td>\n",
       "      <td>3053603</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PW</td>\n",
       "      <td>Power REIT</td>\n",
       "      <td>0001532619</td>\n",
       "      <td>3181196</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>2026-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker                                company_name         cik  market_cap  \\\n",
       "0    PLYM              Plymouth Industrial REIT, Inc.  0001515816   987534080   \n",
       "1     MFA                         MFA FINANCIAL, INC.  0001055160   989212992   \n",
       "2    GMRE                    Global Medical REIT Inc.  0001533615   960033728   \n",
       "3     AIV        APARTMENT INVESTMENT & MANAGEMENT CO  0000922864   848316736   \n",
       "4    FBRT             Franklin BSP Realty Trust, Inc.  0001562528   813286912   \n",
       "..    ...                                         ...         ...         ...   \n",
       "66   SQFT               Presidio Property Trust, Inc.  0001080657     5202343   \n",
       "67   GIPR          GENERATION INCOME PROPERTIES, INC.  0001651721     4491688   \n",
       "68   WHLR  Wheeler Real Estate Investment Trust, Inc.  0001527541     3217630   \n",
       "69   CMCT       Creative Media & Community Trust Corp  0000908311     3053603   \n",
       "70     PW                                  Power REIT  0001532619     3181196   \n",
       "\n",
       "         sector reit_type geography  is_active  date_added last_updated  \n",
       "0   Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "1   Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "2   Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "3   Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "4   Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "..          ...       ...       ...        ...         ...          ...  \n",
       "66  Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "67  Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "68  Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "69  Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "70  Real Estate    Equity        US          1  2026-01-13   2026-01-13  \n",
       "\n",
       "[71 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path = \"version2/data/database/reit_scanner.db\"\n",
    "ticker = \"NLOP\"   # change this\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "ticker_flags = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM reits\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "ticker_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "152a6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 370 distress flags to version2/data/processed/Version2.xlsx\n"
     ]
    }
   ],
   "source": [
    "db_path = \"version2/data/database/reit_scanner.db\"\n",
    "ticker = \"NLOP\"   # change this\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "ticker_flags = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        d.ticker,\n",
    "        r.company_name,\n",
    "        r.market_cap,\n",
    "        d.filing_id,\n",
    "        f.filing_type,\n",
    "        f.filing_date,\n",
    "        f.file_url,\n",
    "        d.flag_category,\n",
    "        d.severity,\n",
    "        d.description,\n",
    "        d.supporting_quote\n",
    "    FROM distress_flags d \n",
    "    JOIN filings f ON d.filing_id = f.accession_number\n",
    "    JOIN reits r ON d.ticker = r.ticker\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "ticker_flags\n",
    "with pd.ExcelWriter('version2/data/processed/Version2.xlsx', engine='openpyxl') as writer:\n",
    "    ticker_flags.to_excel(writer, sheet_name='Version2', index=False)\n",
    "\n",
    "print(f\"✓ Saved {len(ticker_flags)} distress flags to version2/data/processed/Version2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af20ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 218 REIT scores to data/processed/distress_flags.xlsx (sheet: reit_scores)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = \"version2/data/database/reit_scanner.db\"\n",
    "ticker = \"NLOP\"   # change this\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "ticker_flags = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        ticker,\n",
    "        period_end_date,\n",
    "        leverage_score,\n",
    "        liquidity_score,\n",
    "        distress_score,\n",
    "        final_score,\n",
    "        rank\n",
    "    FROM reit_scores\n",
    "    ORDER BY rank\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "ticker_flags\n",
    "with pd.ExcelWriter('version2/data/processed/distress_flags.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    ticker_flags.to_excel(writer, sheet_name='reit_scores', index=False)\n",
    "\n",
    "print(f\"✓ Saved {len(ticker_flags)} REIT scores to version2/data/processed/distress_flags.xlsx (sheet: reit_scores)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 117 REIT records to data/processed/distress_flags.xlsx (sheet: reits)\n"
     ]
    }
   ],
   "source": [
    "db_path = \"version2/data/database/reit_scanner.db\"\n",
    "ticker = \"NLOP\"   # change this\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "ticker_flags = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "    ticker,\n",
    "    company_name,\n",
    "    market_cap,\n",
    "    geography\n",
    "    FROM reits\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "with pd.ExcelWriter('version2/data/processed/distress_flags.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    ticker_flags.to_excel(writer, sheet_name='reits', index=False)\n",
    "\n",
    "print(f\"✓ Saved {len(ticker_flags)} REIT records to version2/data/processed/distress_flags.xlsx (sheet: reits)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
